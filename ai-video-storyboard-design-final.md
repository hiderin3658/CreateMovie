# AIãƒ“ãƒ‡ã‚ªåˆ¶ä½œã‚¹ã‚­ãƒ«ï¼ˆai-video-storyboardï¼‰è©³ç´°è¨­è¨ˆæ›¸

## 1. ã‚¹ã‚­ãƒ«æ¦‚è¦

### 1.1 å®Ÿè£…åŸºç›¤

ã“ã®ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã¯ **Claude Code Skills** ã‚’ä½¿ç”¨ã—ã¦å®Ÿè£…ã•ã‚Œã¦ã„ã¾ã™ã€‚

**Claude Skillsã¨ã¯:**
- Anthropicç¤¾ãŒæä¾›ã™ã‚‹Claude AIã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®æ‹¡å¼µæ©Ÿèƒ½ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯
- ç‰¹å®šã®ã‚¿ã‚¹ã‚¯ã‚„ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã‚’è‡ªç„¶è¨€èªã§æŒ‡ç¤ºã™ã‚‹ã ã‘ã§è‡ªå‹•å®Ÿè¡Œã§ãã‚‹ä»•çµ„ã¿
- Claude Code on the webã€CLIã€Desktopã€APIã®å…¨ã¦ã®Claudeç’°å¢ƒã§å‹•ä½œ

**æœ¬ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã§ã®æ´»ç”¨:**
- `.claude/skills/ai-video-storyboard/SKILL.md` ã«ã‚¹ã‚­ãƒ«å®šç¾©ã‚’é…ç½®
- Claudeã«ã€Œå‹•ç”»ã®çµµã‚³ãƒ³ãƒ†ã‚’ä½œæˆã—ã¦ã€ã¨ä¾é ¼ã™ã‚‹ã ã‘ã§ã€è‡ªå‹•çš„ã«ã“ã®ã‚¹ã‚­ãƒ«ãŒèµ·å‹•
- ã‚¹ã‚¯ãƒªãƒ—ãƒˆã®ç›´æ¥å®Ÿè¡Œã ã‘ã§ãªãã€å¯¾è©±çš„ãªãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã§ã‚‚ä½¿ç”¨å¯èƒ½
- ãƒãƒ¼ãƒ å†…ã§å…±æœ‰å¯èƒ½ãªãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã‚¹ã‚­ãƒ«ã¨ã—ã¦è¨­è¨ˆ

### 1.2 ç›®çš„
AIãƒ“ãƒ‡ã‚ªåˆ¶ä½œã«ãŠã‘ã‚‹çµµã‚³ãƒ³ãƒ†ç”Ÿæˆã€ç”»åƒç”Ÿæˆã€å‹•ç”»ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆä½œæˆã‚’è‡ªå‹•åŒ–ã—ã€1åˆ†é–“ã®å‹•ç”»ï¼ˆ6-10ã‚«ãƒƒãƒˆï¼‰ã®åˆ¶ä½œãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã‚’åŠ¹ç‡åŒ–ã™ã‚‹ã‚¹ã‚­ãƒ«ã€‚

### 1.3 ä¸»è¦æ©Ÿèƒ½
- **çµµã‚³ãƒ³ãƒ†è‡ªå‹•ç”Ÿæˆ**: ã‚¹ãƒˆãƒ¼ãƒªãƒ¼ã‚³ãƒ³ã‚»ãƒ—ãƒˆã‹ã‚‰6-10ã‚«ãƒƒãƒˆã®æ§‹æˆã‚’è‡ªå‹•ç”Ÿæˆ
- **ç”»åƒç”Ÿæˆ**: Gemini APIï¼ˆImagen 3ï¼‰ã‚’ä½¿ç”¨ã—ãŸå„ã‚«ãƒƒãƒˆã®æœ€åˆã®ãƒ•ãƒ¬ãƒ¼ãƒ ç”»åƒç”Ÿæˆ
- **ItoVãƒ—ãƒ­ãƒ³ãƒ—ãƒˆç”Ÿæˆ**: ç”»åƒã‹ã‚‰å‹•ç”»ã¸ã®å¤‰æ›ç”¨ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆè‡ªå‹•ç”Ÿæˆ
- **æ§‹å›³ãƒ»ã‚«ãƒ¡ãƒ©ãƒ¯ãƒ¼ã‚¯é¸æŠ**: ã‚·ãƒ¼ãƒ³ã«é©ã—ãŸæ§‹å›³ã¨ã‚«ãƒ¡ãƒ©ãƒ¯ãƒ¼ã‚¯ã®è‡ªå‹•é¸æŠ
- **ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼ä¸€è²«æ€§ç®¡ç†**: ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼ã®å¤–è¦‹ã¨ç‰¹å¾´ã®ä¸€è²«æ€§ç¶­æŒ

### 1.4 å¯¾è±¡ãƒ¦ãƒ¼ã‚¶ãƒ¼
- æ•™è‚²ã‚³ãƒ³ãƒ†ãƒ³ãƒ„åˆ¶ä½œè€…
- ãƒãƒ¼ã‚±ãƒ†ã‚£ãƒ³ã‚°å‹•ç”»åˆ¶ä½œè€…
- ã‚¢ãƒ‹ãƒ¡ãƒ¼ã‚·ãƒ§ãƒ³åˆ¶ä½œåˆå¿ƒè€…
- AIãƒ„ãƒ¼ãƒ«ã‚’æ´»ç”¨ã—ãŸå‹•ç”»åˆ¶ä½œè€…

## 2. ã‚¹ã‚­ãƒ«æ§‹é€ 

### 2.1 ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªæ§‹æˆ

```
ai-video-storyboard/
â”œâ”€â”€ SKILL.md                        # ã‚¹ã‚­ãƒ«ã®ãƒ¡ã‚¤ãƒ³ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆï¼ˆå¿…é ˆï¼‰
â”œâ”€â”€ scripts/                         # å®Ÿè¡Œå¯èƒ½ã‚¹ã‚¯ãƒªãƒ—ãƒˆ
â”‚   â”œâ”€â”€ generate_storyboard.py      # ãƒ¡ã‚¤ãƒ³çµµã‚³ãƒ³ãƒ†ç”Ÿæˆã‚¹ã‚¯ãƒªãƒ—ãƒˆ
â”‚   â”œâ”€â”€ generate_images.py          # Imagen 3ç”»åƒç”Ÿæˆ
â”‚   â”œâ”€â”€ generate_prompts.py         # ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆç”Ÿæˆãƒ­ã‚¸ãƒƒã‚¯
â”‚   â”œâ”€â”€ character_consistency.py    # ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼ä¸€è²«æ€§ç®¡ç†
â”‚   â””â”€â”€ utils.py                    # å…±é€šãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£
â”œâ”€â”€ references/                      # ãƒªãƒ•ã‚¡ãƒ¬ãƒ³ã‚¹ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ
â”‚   â”œâ”€â”€ camera_shots.md             # ã‚«ãƒ¡ãƒ©ã‚·ãƒ§ãƒƒãƒˆè¾æ›¸
â”‚   â”œâ”€â”€ composition_guide.md        # æ§‹å›³ã‚¬ã‚¤ãƒ‰
â”‚   â”œâ”€â”€ camera_movements.md         # ã‚«ãƒ¡ãƒ©ãƒ ãƒ¼ãƒ–ãƒ¡ãƒ³ãƒˆå‚ç…§
â”‚   â”œâ”€â”€ itov_patterns.md           # ItoVãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒ‘ã‚¿ãƒ¼ãƒ³é›†
â”‚   â””â”€â”€ troubleshooting.md         # ãƒˆãƒ©ãƒ–ãƒ«ã‚·ãƒ¥ãƒ¼ãƒ†ã‚£ãƒ³ã‚°ã‚¬ã‚¤ãƒ‰
â””â”€â”€ assets/                         # ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã¨ã‚µãƒ³ãƒ—ãƒ«
    â”œâ”€â”€ templates/
    â”‚   â”œâ”€â”€ storyboard_template.json
    â”‚   â”œâ”€â”€ character_sheet.json
    â”‚   â””â”€â”€ shot_list_template.md
    â””â”€â”€ examples/
        â”œâ”€â”€ sample_storyboards/
        â”‚   â”œâ”€â”€ educational_video.json
        â”‚   â”œâ”€â”€ marketing_video.json
        â”‚   â””â”€â”€ narrative_video.json
        â””â”€â”€ sample_prompts.json
```

## 3. ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆè©³ç´°è¨­è¨ˆ

### 3.1 SKILL.md

```yaml
---
name: ai-video-storyboard
description: AI video production assistant for creating storyboards, image prompts, and ItoV prompts for 1-minute videos (6-10 cuts). Generates first-frame images using Gemini API (Imagen 3). Automatically selects optimal compositions and camera work. Use when creating AI-generated videos, storyboards, video production planning, or educational content with visual narratives.
---
```

ä¸»è¦ã‚»ã‚¯ã‚·ãƒ§ãƒ³ï¼š
- **Prerequisites**: Gemini API ã‚­ãƒ¼ã®è¨­å®šæ–¹æ³•
- **Quick Start**: åŸºæœ¬çš„ãªä½¿ç”¨æ–¹æ³•
- **Workflow**: ã‚¹ãƒ†ãƒƒãƒ—ãƒã‚¤ã‚¹ãƒ†ãƒƒãƒ—ã®ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼
- **Advanced Features**: é«˜åº¦ãªæ©Ÿèƒ½ã¨è¨­å®š
- **Troubleshooting**: ã‚ˆãã‚ã‚‹å•é¡Œã¨è§£æ±ºç­–

### 3.2 ã‚¹ã‚¯ãƒªãƒ—ãƒˆè©³ç´°

#### 3.2.1 generate_storyboard.py
**ç›®çš„**: ãƒ¡ã‚¤ãƒ³ã‚¨ãƒ³ãƒˆãƒªãƒ¼ãƒã‚¤ãƒ³ãƒˆã€å…¨ä½“ã®ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼åˆ¶å¾¡

**ä¸»è¦æ©Ÿèƒ½**:
```python
def create_complete_storyboard(story_description, config=None):
    """
    Parameters:
    - story_description: ã‚¹ãƒˆãƒ¼ãƒªãƒ¼ã®èª¬æ˜æ–‡
    - config: è¨­å®šã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼ˆduration, num_cuts, style, etc.ï¼‰
    
    Returns:
    - StoryboardData: å®Œå…¨ãªçµµã‚³ãƒ³ãƒ†ãƒ‡ãƒ¼ã‚¿
    """
```

**å‡¦ç†ãƒ•ãƒ­ãƒ¼**:
1. ã‚¹ãƒˆãƒ¼ãƒªãƒ¼åˆ†æã¨ã‚«ãƒƒãƒˆåˆ†å‰²
2. å„ã‚«ãƒƒãƒˆã®è©³ç´°è¨­è¨ˆ
3. ç”»åƒãƒ—ãƒ­ãƒ³ãƒ—ãƒˆç”Ÿæˆ
4. ItoVãƒ—ãƒ­ãƒ³ãƒ—ãƒˆç”Ÿæˆ
5. ç”»åƒç”Ÿæˆ
6. ãƒ¬ãƒãƒ¼ãƒˆå‡ºåŠ›

#### 3.2.2 generate_images.py
**ç›®çš„**: Gemini APIçµŒç”±ã§Imagen 3ã‚’ä½¿ç”¨ã—ãŸç”»åƒç”Ÿæˆ

**ä¸»è¦æ©Ÿèƒ½**:
```python
def generate_first_frames(prompts, output_dir):
    """
    å„ã‚«ãƒƒãƒˆã®æœ€åˆã®ãƒ•ãƒ¬ãƒ¼ãƒ ç”»åƒã‚’ç”Ÿæˆ
    
    Parameters:
    - prompts: ç”»åƒç”Ÿæˆãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã®ãƒªã‚¹ãƒˆ
    - output_dir: å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
    
    Returns:
    - List[GeneratedImage]: ç”Ÿæˆã•ã‚ŒãŸç”»åƒæƒ…å ±
    """
```

**ã‚¨ãƒ©ãƒ¼å‡¦ç†**:
- APIåˆ¶é™ã®ç®¡ç†
- ç”»åƒç”Ÿæˆå¤±æ•—æ™‚ã®ãƒªãƒˆãƒ©ã‚¤
- ã‚»ãƒ¼ãƒ•ãƒ†ã‚£ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼å¯¾å¿œ

#### 3.2.3 generate_prompts.py
**ç›®çš„**: åŠ¹æœçš„ãªãƒ—ãƒ­ãƒ³ãƒ—ãƒˆç”Ÿæˆãƒ­ã‚¸ãƒƒã‚¯

**ä¸»è¦æ©Ÿèƒ½**:
```python
def create_image_prompt(scene_data):
    """é™æ­¢ç”»ç”¨ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆç”Ÿæˆ"""
    
def create_video_prompt(scene_data, image_path):
    """ItoVç”¨å‹•ç”»ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆç”Ÿæˆ"""
    
def optimize_prompt(prompt, style_guide):
    """ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã®æœ€é©åŒ–ã¨æ”¹å–„"""
```

#### 3.2.4 character_consistency.py
**ç›®çš„**: ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼ã®ä¸€è²«æ€§ç®¡ç†

**ä¸»è¦æ©Ÿèƒ½**:
```python
class CharacterManager:
    def register_character(self, character_data):
        """ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼æƒ…å ±ã®ç™»éŒ²"""
    
    def get_character_prompt(self, character_id, scene_context):
        """ã‚·ãƒ¼ãƒ³ã«å¿œã˜ãŸã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆç”Ÿæˆ"""
    
    def maintain_consistency(self, prompts):
        """è¤‡æ•°ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆé–“ã®ä¸€è²«æ€§ãƒã‚§ãƒƒã‚¯"""
```

#### 3.2.5 video_model_optimizer.py
**ç›®çš„**: Veo3.1/Sora2ãƒ¢ãƒ‡ãƒ«åˆ¥ã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆæœ€é©åŒ–

**ä¸»è¦æ©Ÿèƒ½**:
```python
class VideoModelOptimizer:
    def __init__(self, target_model="auto"):
        """
        target_model: "veo3", "sora2", "auto"(ä¸¡æ–¹ç”Ÿæˆ)
        """
        self.model = target_model
    
    def generate_optimized_prompt(self, scene_data):
        """ãƒ¢ãƒ‡ãƒ«åˆ¥æœ€é©åŒ–ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆç”Ÿæˆ"""
        if self.model == "veo3":
            return self._generate_veo3_prompt(scene_data)
        elif self.model == "sora2":
            return self._generate_sora2_prompt(scene_data)
        else:  # auto
            return {
                "veo3": self._generate_veo3_prompt(scene_data),
                "sora2": self._generate_sora2_prompt(scene_data)
            }
    
    def _generate_veo3_prompt(self, scene_data):
        """Veo3.1ç”¨: æŠ€è¡“çš„ãƒ»æ§‹é€ åŒ–ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ"""
        # ãƒ•ãƒ¬ãƒ¼ãƒ å˜ä½ã®ç²¾å¯†åˆ¶å¾¡
        # æ˜ ç”»æ’®å½±ç”¨èªã®ä½¿ç”¨
        # ã‚¿ã‚¤ãƒ ãƒ©ã‚¤ãƒ³å½¢å¼ã®ã‚¢ã‚¯ã‚·ãƒ§ãƒ³è¨˜è¿°
        
    def _generate_sora2_prompt(self, scene_data):
        """Sora2ç”¨: æå†™çš„ãƒ»ç‰©èªå‹ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ"""
        # è‡ªç„¶è¨€èªã§ã®æµã‚Œã‚‹è¨˜è¿°
        # æ„Ÿæƒ…ã‚„é›°å›²æ°—ã®è©©çš„è¡¨ç¾
        # ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆé‡è¦–ã®æ§‹æˆ
    
    def convert_between_models(self, prompt, from_model, to_model):
        """ãƒ¢ãƒ‡ãƒ«é–“ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆå¤‰æ›"""
    
    def recommend_model(self, scene_type):
        """ã‚·ãƒ¼ãƒ³ã‚¿ã‚¤ãƒ—ã«åŸºã¥ãæœ€é©ãƒ¢ãƒ‡ãƒ«æ¨å¥¨"""
```

**ãƒ¢ãƒ‡ãƒ«åˆ¥ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆç‰¹æ€§**:

| ç‰¹æ€§ | Veo3.1 | Sora2 |
|------|--------|-------|
| **æ§‹é€ ** | ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿åˆ—æŒ™å‹ | ç‰©èªãƒ»æå†™å‹ |
| **æ™‚é–“åˆ¶å¾¡** | `0-5s: action` | ã€Œå¾ã€…ã«ï½ã€ |
| **ã‚«ãƒ¡ãƒ©** | `Dolly in 2m/s` | ã€Œã‚«ãƒ¡ãƒ©ãŒè¿‘ã¥ãã€ |
| **ã‚¹ã‚¿ã‚¤ãƒ«** | `24fps, f/2.8` | ã€Œæ˜ ç”»ã®ã‚ˆã†ãªã€ |

#### 3.2.6 visual_reference_analyzer.py
**ç›®çš„**: ã‚­ãƒ¼ãƒ“ã‚¸ãƒ¥ã‚¢ãƒ«ç”»åƒã®åˆ†æã¨ä¸–ç•Œè¦³ã®æŠ½å‡º

**ä¸»è¦æ©Ÿèƒ½**:
```python
class VisualReferenceAnalyzer:
    def analyze_key_visual(self, image_path):
        """ã‚­ãƒ¼ãƒ“ã‚¸ãƒ¥ã‚¢ãƒ«ã‹ã‚‰ä¸–ç•Œè¦³ã‚’åˆ†æ"""
        return {
            'style': self._detect_art_style(image_path),
            'color_palette': self._extract_colors(image_path),
            'composition': self._analyze_composition(image_path),
            'mood': self._detect_mood(image_path),
            'elements': self._identify_elements(image_path)
        }
    
    def apply_to_prompts(self, prompts, visual_analysis):
        """åˆ†æçµæœã‚’å…¨ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã«é©ç”¨"""
        style_tokens = self._generate_style_tokens(visual_analysis)
        for prompt in prompts:
            prompt.add_style_reference(style_tokens)
        return prompts
    
    def generate_consistency_guide(self, visual_analysis):
        """ãƒ“ã‚¸ãƒ¥ã‚¢ãƒ«ä¸€è²«æ€§ã‚¬ã‚¤ãƒ‰ãƒ©ã‚¤ãƒ³ç”Ÿæˆ"""
        return {
            'must_include': [],  # å¿…é ˆè¦ç´ 
            'color_guide': {},   # è‰²å½©ã‚¬ã‚¤ãƒ‰
            'style_reference': {} # ã‚¹ã‚¿ã‚¤ãƒ«å‚ç…§
        }
```

**ç”»åƒåˆ†æãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿**:
- **ã‚¹ã‚¿ã‚¤ãƒ«æ¤œå‡º**: ã‚¤ãƒ©ã‚¹ãƒˆ/å†™å®Ÿ/ã‚¢ãƒ‹ãƒ¡/æ°´å½©ãªã©
- **è‰²å½©æŠ½å‡º**: ä¸»è¦5è‰²ã¨ãã®æ¯”ç‡
- **æ§‹å›³åˆ†æ**: ä¸‰åˆ†å‰²æ³•/ä¸­å¿ƒæ§‹å›³/å¯¾è§’ç·šãªã©
- **ãƒ ãƒ¼ãƒ‰åˆ¤å®š**: æ˜ã‚‹ã„/æš—ã„/ç¥ç§˜çš„/æ´»ç™ºãªã©
- **è¦ç´ è­˜åˆ¥**: äººç‰©/å»ºç‰©/è‡ªç„¶/ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆ

#### 3.2.7 music_prompt_generator.py
**ç›®çš„**: Sunoç”¨éŸ³æ¥½ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã®ç”Ÿæˆ

**ä¸»è¦æ©Ÿèƒ½**:
```python
class MusicPromptGenerator:
    def analyze_emotional_arc(self, storyboard):
        """ã‚¹ãƒˆãƒ¼ãƒªãƒ¼ã®æ„Ÿæƒ…æ›²ç·šã‚’åˆ†æ"""
        return {
            'arc_type': 'rising/falling/wave',
            'peak_points': [],
            'mood_transitions': []
        }
    
    def divide_music_sections(self, storyboard):
        """éŸ³æ¥½ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã®åˆ†å‰²ææ¡ˆ"""
        sections = []
        # æ„Ÿæƒ…ã®å¤‰åŒ–ç‚¹ã§åŒºåˆ‡ã‚‹
        # 3-4ã‚«ãƒƒãƒˆã‚’1ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã®ç›®å®‰
        return sections
    
    def generate_suno_prompts(self, sections):
        """Sunoæœ€é©åŒ–ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆç”Ÿæˆ"""
        prompts = []
        for section in sections:
            prompt = {
                'cuts': section['cut_range'],
                'duration': section['duration'],
                'style': self._determine_music_style(section),
                'tempo': self._calculate_tempo(section),
                'mood': section['mood'],
                'instruments': self._suggest_instruments(section),
                'suno_prompt': self._build_suno_prompt(section)
            }
            prompts.append(prompt)
        return prompts
    
    def _build_suno_prompt(self, section):
        """Sunoç”¨ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆæ§‹ç¯‰"""
        # SunoãŒç†è§£ã—ã‚„ã™ã„å½¢å¼
        # ã‚¸ãƒ£ãƒ³ãƒ«ã€BPMã€æ¥½å™¨ã€ãƒ ãƒ¼ãƒ‰
        template = "[{genre}] {tempo}bpm, {mood}, {instruments}"
        return template.format(**section)
```

**éŸ³æ¥½ã‚»ã‚¯ã‚·ãƒ§ãƒ³åˆ†å‰²ä¾‹**:
```python
{
    "section_1": {
        "cuts": "1-3",
        "duration": "25s",
        "description": "ã‚ªãƒ¼ãƒ—ãƒ‹ãƒ³ã‚°ãƒ»å°å…¥",
        "suno_prompt": "[Cinematic Orchestra] 80bpm, mysterious, strings and piano"
    },
    "section_2": {
        "cuts": "4-6",
        "duration": "20s", 
        "description": "å±•é–‹ãƒ»ã‚¢ã‚¯ã‚·ãƒ§ãƒ³",
        "suno_prompt": "[Epic Hybrid] 140bpm, intense, drums and brass"
    },
    "section_3": {
        "cuts": "7-8",
        "duration": "15s",
        "description": "è§£æ±ºãƒ»ã‚¨ãƒ³ãƒ‡ã‚£ãƒ³ã‚°",
        "suno_prompt": "[Emotional Piano] 70bpm, uplifting, piano and strings"
    }
}
```

#### 3.2.6 image_analyzer.py
**ç›®çš„**: ã‚­ãƒ¼ãƒ“ã‚¸ãƒ¥ã‚¢ãƒ«ç”»åƒã®è§£æã¨ä¸–ç•Œè¦³æŠ½å‡º

**ä¸»è¦æ©Ÿèƒ½**:
```python
class ImageAnalyzer:
    def __init__(self, api_key=None):
        """Gemini Vision APIã‚’ä½¿ç”¨ã—ãŸç”»åƒè§£æ"""
        self.client = genai.Client(api_key=api_key)
    
    def analyze_key_visual(self, image_path):
        """ã‚­ãƒ¼ãƒ“ã‚¸ãƒ¥ã‚¢ãƒ«ã‹ã‚‰ä¸–ç•Œè¦³ã‚’æŠ½å‡º"""
        return {
            "style": self._detect_art_style(image_path),
            "colors": self._extract_color_palette(image_path),
            "mood": self._analyze_mood(image_path),
            "elements": self._identify_key_elements(image_path),
            "composition": self._analyze_composition(image_path)
        }
    
    def _detect_art_style(self, image_path):
        """ã‚¢ãƒ¼ãƒˆã‚¹ã‚¿ã‚¤ãƒ«ã®æ¤œå‡º"""
        # ã‚¢ãƒ‹ãƒ¡ã€ãƒªã‚¢ãƒ«ã€ã‚¤ãƒ©ã‚¹ãƒˆã€3DCGãªã©
        prompt = """
        Analyze the art style of this image:
        - Animation style (anime, cartoon, realistic, etc.)
        - Rendering technique (2D, 3D, painted, etc.)
        - Visual characteristics
        Return as structured data.
        """
        
    def _extract_color_palette(self, image_path):
        """ä¸»è¦ãªè‰²å½©ã®æŠ½å‡º"""
        # æ”¯é…çš„ãªè‰²ã€è‰²æ¸©åº¦ã€ã‚³ãƒ³ãƒˆãƒ©ã‚¹ãƒˆãªã©
        
    def _analyze_mood(self, image_path):
        """é›°å›²æ°—ãƒ»ãƒ ãƒ¼ãƒ‰ã®åˆ†æ"""
        # æ˜ã‚‹ã„ã€æš—ã„ã€ç¥ç§˜çš„ã€æ´»æ°—ãŒã‚ã‚‹ãªã©
        
    def generate_style_guide(self, analysis_result):
        """è§£æçµæœã‹ã‚‰ã‚¹ã‚¿ã‚¤ãƒ«ã‚¬ã‚¤ãƒ‰ã‚’ç”Ÿæˆ"""
        return {
            "prompt_modifiers": [],  # å…¨ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã«è¿½åŠ ã™ã‚‹ä¿®é£¾å­
            "technical_specs": {},    # æŠ€è¡“ä»•æ§˜
            "consistency_rules": []   # ä¸€è²«æ€§ç¶­æŒã®ãƒ«ãƒ¼ãƒ«
        }
    
    def apply_to_prompts(self, prompts, style_guide):
        """ã‚¹ã‚¿ã‚¤ãƒ«ã‚¬ã‚¤ãƒ‰ã‚’å„ã‚«ãƒƒãƒˆã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã«é©ç”¨"""
        for prompt in prompts:
            prompt.update(style_guide["prompt_modifiers"])
        return prompts
```

**ç”»åƒè§£æã«ã‚ˆã‚‹ä¸–ç•Œè¦³çµ±ä¸€**:
- è‰²å½©ã®ä¸€è²«æ€§ï¼ˆã‚«ãƒ©ãƒ¼ãƒ‘ãƒ¬ãƒƒãƒˆå…±æœ‰ï¼‰
- ã‚¹ã‚¿ã‚¤ãƒ«ã®çµ±ä¸€ï¼ˆã‚¢ãƒ¼ãƒˆã‚¹ã‚¿ã‚¤ãƒ«ç¶­æŒï¼‰
- é›°å›²æ°—ã®ç¶™ç¶šï¼ˆãƒ ãƒ¼ãƒ‰ä¿æŒï¼‰
- æ§‹å›³ãƒ‘ã‚¿ãƒ¼ãƒ³ã®æ´»ç”¨

#### 3.2.7 music_prompt_generator.py
**ç›®çš„**: Sunoå‘ã‘BGMãƒ—ãƒ­ãƒ³ãƒ—ãƒˆç”Ÿæˆ

**ä¸»è¦æ©Ÿèƒ½**:
```python
class MusicPromptGenerator:
    def __init__(self):
        """éŸ³æ¥½ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆç”Ÿæˆå™¨ã®åˆæœŸåŒ–"""
        self.music_styles = self._load_music_styles()
    
    def analyze_emotional_arc(self, storyboard):
        """ã‚¹ãƒˆãƒ¼ãƒªãƒ¼ã®æ„Ÿæƒ…æ›²ç·šã‚’åˆ†æ"""
        emotional_curve = []
        for cut in storyboard.cuts:
            emotion = self._detect_emotion(cut)
            emotional_curve.append({
                "cut": cut.cut_number,
                "emotion": emotion,
                "intensity": self._measure_intensity(cut)
            })
        return emotional_curve
    
    def create_music_sections(self, storyboard):
        """éŸ³æ¥½ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã®å®šç¾©ï¼ˆè¤‡æ•°ã‚«ãƒƒãƒˆã‚’ã‚°ãƒ«ãƒ¼ãƒ—åŒ–ï¼‰"""
        sections = []
        current_section = []
        current_mood = None
        
        for cut in storyboard.cuts:
            cut_mood = self._get_cut_mood(cut)
            
            if current_mood != cut_mood:
                if current_section:
                    sections.append(current_section)
                current_section = [cut]
                current_mood = cut_mood
            else:
                current_section.append(cut)
        
        if current_section:
            sections.append(current_section)
        
        return sections
    
    def generate_suno_prompts(self, music_sections, storyboard):
        """Sunoå‘ã‘ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆç”Ÿæˆ"""
        suno_prompts = []
        
        for i, section in enumerate(music_sections):
            prompt = self._create_single_suno_prompt(
                section,
                storyboard.style_guide,
                position=i  # intro, main, climax, outro
            )
            
            suno_prompts.append({
                "section_id": i + 1,
                "cuts": [cut.cut_number for cut in section],
                "duration": sum(cut.duration for cut in section),
                "prompt": prompt,
                "style_tags": self._get_style_tags(section),
                "bpm_suggestion": self._suggest_bpm(section)
            })
        
        return suno_prompts
    
    def _create_single_suno_prompt(self, section, style_guide, position):
        """å˜ä¸€ã‚»ã‚¯ã‚·ãƒ§ãƒ³ç”¨ã®Sunoãƒ—ãƒ­ãƒ³ãƒ—ãƒˆä½œæˆ"""
        
        # ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã®ç‰¹å¾´ã‚’åˆ†æ
        mood = self._analyze_section_mood(section)
        energy = self._calculate_energy_level(section)
        
        # ä½ç½®ã«å¿œã˜ãŸæ§‹æˆ
        structure = {
            0: "intro",  # å°å…¥éƒ¨
            -1: "outro",  # çµ‚çµéƒ¨
        }.get(position, "main")
        
        # ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆ
        template = f"""
        [{mood} {structure}]
        Style: {style_guide.get('music_genre', 'cinematic')}
        Energy: {energy}/10
        Instruments: {self._suggest_instruments(mood, energy)}
        Mood: {self._describe_mood(section)}
        """
        
        return template.strip()
    
    def _suggest_instruments(self, mood, energy):
        """ãƒ ãƒ¼ãƒ‰ã¨ã‚¨ãƒãƒ«ã‚®ãƒ¼ã«åŸºã¥ãæ¥½å™¨ææ¡ˆ"""
        instrument_map = {
            ("calm", "low"): ["piano", "strings", "ambient pad"],
            ("tense", "high"): ["drums", "bass", "synth", "orchestra hits"],
            ("happy", "medium"): ["acoustic guitar", "light percussion", "bells"],
            ("sad", "low"): ["cello", "violin", "piano"],
            ("epic", "high"): ["full orchestra", "choir", "timpani"]
        }
        
    def generate_timing_sheet(self, suno_prompts, storyboard):
        """ã‚¿ã‚¤ãƒŸãƒ³ã‚°ã‚·ãƒ¼ãƒˆç”Ÿæˆï¼ˆåŒæœŸç”¨ï¼‰"""
        timing = []
        current_time = 0
        
        for prompt_data in suno_prompts:
            timing.append({
                "section": prompt_data["section_id"],
                "start_time": current_time,
                "end_time": current_time + prompt_data["duration"],
                "cuts": prompt_data["cuts"],
                "cue_points": self._identify_cue_points(prompt_data, storyboard)
            })
            current_time += prompt_data["duration"]
        
        return timing
```

**éŸ³æ¥½ã‚»ã‚¯ã‚·ãƒ§ãƒ³åˆ†å‰²ãƒ‘ã‚¿ãƒ¼ãƒ³**:

| ãƒ‘ã‚¿ãƒ¼ãƒ³ | èª¬æ˜ | é©ç”¨ä¾‹ |
|---------|------|--------|
| **3åˆ†å‰²** | ã‚¤ãƒ³ãƒˆãƒ­ãƒ»ãƒ¡ã‚¤ãƒ³ãƒ»ã‚¢ã‚¦ãƒˆãƒ­ | çŸ­ã„å‹•ç”»ã€ã‚·ãƒ³ãƒ—ãƒ«ãªæ§‹æˆ |
| **èµ·æ‰¿è»¢çµ** | 4ã‚»ã‚¯ã‚·ãƒ§ãƒ³æ§‹æˆ | ç‰©èªæ€§ã®ã‚ã‚‹å‹•ç”» |
| **æ„Ÿæƒ…åˆ¥** | æ„Ÿæƒ…ã®å¤‰åŒ–ã§ã‚»ã‚¯ã‚·ãƒ§ãƒ³åˆ†ã‘ | ãƒ‰ãƒ©ãƒãƒãƒƒã‚¯ãªå±•é–‹ |
| **ã‚·ãƒ¼ãƒ³åˆ¥** | å ´é¢è»¢æ›ã§åŒºåˆ‡ã‚‹ | å ´æ‰€ã‚„æ™‚é–“ãŒå¤‰ã‚ã‚‹å‹•ç”» |

### 3.3 ãƒªãƒ•ã‚¡ãƒ¬ãƒ³ã‚¹ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆï¼ˆè‡ªå‹•é¸æŠï¼‹å­¦ç¿’ç”¨ï¼‰

#### è¨­è¨ˆæ–¹é‡ï¼šè‡ªå‹•é¸æŠã‚’åŸºæœ¬ã¨ã—ãŸã‚¤ãƒ†ãƒ¬ãƒ¼ãƒ†ã‚£ãƒ–æ”¹å–„

**åŸºæœ¬ãƒ•ãƒ­ãƒ¼**ï¼š
1. **è‡ªå‹•ç”Ÿæˆ** â†’ AIãŒæœ€é©ãªã‚«ãƒ¡ãƒ©ãƒ¯ãƒ¼ã‚¯ã‚’è‡ªå‹•é¸æŠ
2. **ç¢ºèª** â†’ ç”Ÿæˆã•ã‚ŒãŸç”»åƒã¨ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ç¢ºèª
3. **èª¿æ•´** â†’ å¿…è¦ã«å¿œã˜ã¦ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ä¿®æ­£ã—ã¦å†ç”Ÿæˆ

#### 3.3.1 camera_shots.mdï¼ˆè©³ç´°è§£èª¬ï¼‹è‡ªå‹•é¸æŠãƒ«ãƒ¼ãƒ«ï¼‰

**è‡ªå‹•é¸æŠãƒ­ã‚¸ãƒƒã‚¯**ï¼š
```python
# ã‚¹ã‚¯ãƒªãƒ—ãƒˆå†…ã§è‡ªå‹•å®Ÿè¡Œã•ã‚Œã‚‹é¸æŠãƒ«ãƒ¼ãƒ«
scene_camera_rules = {
    'establishing': 'ELS',  # å ´æ‰€ã®ç¢ºç«‹
    'character_intro': 'MS',  # ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼ç´¹ä»‹
    'dialogue': 'MS/MCU',  # ä¼šè©±ã‚·ãƒ¼ãƒ³
    'action': 'LS/MS',  # ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã‚·ãƒ¼ãƒ³
    'emotion': 'CU/ECU',  # æ„Ÿæƒ…è¡¨ç¾
    'conclusion': 'LS/ELS'  # ç· ã‚ããã‚Š
}
```

**å„ã‚·ãƒ§ãƒƒãƒˆã®è©³ç´°è§£èª¬**ï¼š

##### Extreme Long Shot (ELS) - è¶…é æ™¯
- **è‡ªå‹•é¸æŠã•ã‚Œã‚‹å ´é¢**: ã‚ªãƒ¼ãƒ—ãƒ‹ãƒ³ã‚°ã€å ´é¢è»¢æ›ã€ã‚¨ãƒ³ãƒ‡ã‚£ãƒ³ã‚°
- **è¦–è¦šåŠ¹æœ**: å£®å¤§ã•ã€å­¤ç‹¬æ„Ÿã€ç’°å¢ƒã¨ã®é–¢ä¿‚æ€§
- **ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰**: `extreme wide shot, aerial view, vast landscape, establishing shot`
- **ä¿®æ­£ã®ãƒ’ãƒ³ãƒˆ**: ã€Œã‚‚ã£ã¨è¿‘ã¥ããŸã„ã€â†’ LS ã«å¤‰æ›´ã€ã€Œãƒ‰ãƒ­ãƒ¼ãƒ³è¦–ç‚¹ã€â†’ `drone aerial view` è¿½åŠ 

##### Long Shot (LS) - é æ™¯  
- **è‡ªå‹•é¸æŠã•ã‚Œã‚‹å ´é¢**: ã‚¢ã‚¯ã‚·ãƒ§ãƒ³å…¨ä½“ã€ã‚°ãƒ«ãƒ¼ãƒ—ã‚·ãƒ§ãƒƒãƒˆ
- **è¦–è¦šåŠ¹æœ**: å…¨èº«ã¨ç’°å¢ƒã®ãƒãƒ©ãƒ³ã‚¹
- **ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰**: `wide shot, full body visible, environmental context`
- **ä¿®æ­£ã®ãƒ’ãƒ³ãƒˆ**: ã€Œè¡¨æƒ…ã‚’è¦‹ãŸã„ã€â†’ MS ã«å¤‰æ›´

##### Medium Shot (MS) - ä¸­æ™¯
- **è‡ªå‹•é¸æŠã•ã‚Œã‚‹å ´é¢**: ä¼šè©±ã€é€šå¸¸ã®ã‚¢ã‚¯ã‚·ãƒ§ãƒ³
- **è¦–è¦šåŠ¹æœ**: è¦ªè¿‘æ„Ÿã¨ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã®ãƒãƒ©ãƒ³ã‚¹
- **ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰**: `medium shot, waist up, conversational distance`
- **ä¿®æ­£ã®ãƒ’ãƒ³ãƒˆ**: ã€Œã‚‚ã£ã¨ãƒ€ã‚¤ãƒŠãƒŸãƒƒã‚¯ã«ã€â†’ ã‚«ãƒ¡ãƒ©ãƒ ãƒ¼ãƒ–ãƒ¡ãƒ³ãƒˆè¿½åŠ 

##### Close-Up (CU) - ã‚¯ãƒ­ãƒ¼ã‚ºã‚¢ãƒƒãƒ—
- **è‡ªå‹•é¸æŠã•ã‚Œã‚‹å ´é¢**: æ„Ÿæƒ…çš„ãªç¬é–“ã€é‡è¦ãªè©³ç´°
- **è¦–è¦šåŠ¹æœ**: è¦ªå¯†ã•ã€æ„Ÿæƒ…ã®å¼·èª¿
- **ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰**: `close-up shot, face and shoulders, emotional focus`
- **ä¿®æ­£ã®ãƒ’ãƒ³ãƒˆ**: ã€Œç›®ã ã‘æ˜ ã—ãŸã„ã€â†’ ECU ã«å¤‰æ›´

##### Extreme Close-Up (ECU) - è¶…ã‚¯ãƒ­ãƒ¼ã‚ºã‚¢ãƒƒãƒ—
- **è‡ªå‹•é¸æŠã•ã‚Œã‚‹å ´é¢**: æ¥µåº¦ã®æ„Ÿæƒ…ã€ç´°éƒ¨ã®å¼·èª¿
- **è¦–è¦šåŠ¹æœ**: ç·Šå¼µæ„Ÿã€é›†ä¸­
- **ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰**: `extreme close-up, eyes only, intense detail`
- **ä¿®æ­£ã®ãƒ’ãƒ³ãƒˆ**: ä½¿ã„ã™ãæ³¨æ„ã€ã‚¤ãƒ³ãƒ‘ã‚¯ãƒˆãŒè–„ã‚Œã‚‹

#### 3.3.2 composition_guide.mdï¼ˆæ§‹å›³ã®è‡ªå‹•é¸æŠã¨èª¿æ•´ï¼‰

**è‡ªå‹•é¸æŠãƒãƒˆãƒªãƒƒã‚¯ã‚¹**ï¼š
```python
composition_matrix = {
    'opening': 'rule_of_thirds',      # å®‰å®šã—ãŸå°å…¥
    'character': 'centered/golden',    # ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼ãƒ•ã‚©ãƒ¼ã‚«ã‚¹
    'dialogue': 'over_shoulder',       # ä¼šè©±ã®è‡ªç„¶ãªæ§‹å›³
    'action': 'diagonal',              # ãƒ€ã‚¤ãƒŠãƒŸãƒƒã‚¯ãªå‹•ã
    'emotion': 'centered_tight',       # æ„Ÿæƒ…ã¸ã®é›†ä¸­
    'landscape': 'golden_ratio'        # ç¾çš„ãªé¢¨æ™¯
}
```

**æ§‹å›³ã‚¿ã‚¤ãƒ—ã¨ä¿®æ­£æ–¹æ³•**ï¼š

##### ä¸‰åˆ†å‰²æ³•ï¼ˆRule of Thirdsï¼‰
- **è‡ªå‹•é©ç”¨**: æ±ç”¨çš„ãªã‚·ãƒ¼ãƒ³ã€é¢¨æ™¯ã€æ—¥å¸¸å ´é¢
- **åŠ¹æœ**: ãƒãƒ©ãƒ³ã‚¹ãŒè‰¯ãã€è‡ªç„¶ãªå°è±¡
- **ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆä¿®æ­£ä¾‹**:
  - åŸºæœ¬: `rule of thirds composition`
  - å¼·èª¿: `subject on left third, looking right`
  - èª¿æ•´: `slightly off-center for dynamic balance`

##### é»„é‡‘æ¯”ï¼ˆGolden Ratioï¼‰  
- **è‡ªå‹•é©ç”¨**: èŠ¸è¡“çš„ãªã‚·ãƒ¼ãƒ³ã€ç¾ã—ã•ã‚’å¼·èª¿ã—ãŸã„å ´é¢
- **åŠ¹æœ**: æ•°å­¦çš„ã«ç¾ã—ã„ã€æ´—ç·´ã•ã‚ŒãŸå°è±¡
- **ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆä¿®æ­£ä¾‹**:
  - åŸºæœ¬: `golden ratio composition`
  - èºæ—‹: `fibonacci spiral composition`
  - èª¿æ•´: `divine proportion layout`

##### ä¸­å¿ƒæ§‹å›³ï¼ˆCentered Compositionï¼‰
- **è‡ªå‹•é©ç”¨**: ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼ç´¹ä»‹ã€ã‚·ãƒ³ãƒ¡ãƒˆãƒªãƒ¼ã€ãƒ•ã‚©ãƒ¼ãƒãƒ«ãªå ´é¢
- **åŠ¹æœ**: åŠ›å¼·ã„ã€ç›´æ¥çš„ã€ãƒ•ã‚©ãƒ¼ãƒãƒ«
- **ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆä¿®æ­£ä¾‹**:
  - åŸºæœ¬: `centered composition, symmetrical`
  - å¼·èª¿: `dead center, perfect symmetry`
  - ç·©å’Œ: `slightly off-center for subtle tension`

##### å¯¾è§’ç·šæ§‹å›³ï¼ˆDiagonal Compositionï¼‰
- **è‡ªå‹•é©ç”¨**: ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã€å‹•ãã®ã‚ã‚‹ã‚·ãƒ¼ãƒ³ã€ç·Šå¼µæ„Ÿ
- **åŠ¹æœ**: ãƒ€ã‚¤ãƒŠãƒŸãƒƒã‚¯ã€ã‚¹ãƒ”ãƒ¼ãƒ‰æ„Ÿã€ä¸å®‰å®šã•
- **ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆä¿®æ­£ä¾‹**:
  - åŸºæœ¬: `diagonal composition, dynamic angles`
  - å¼·èª¿: `strong diagonal lines, 45-degree angle`
  - èª¿æ•´: `subtle diagonal for gentle movement`

#### 3.3.3 camera_movements.mdï¼ˆã‚«ãƒ¡ãƒ©ãƒ¯ãƒ¼ã‚¯ã®è‡ªå‹•é¸æŠï¼‰

**ã‚·ãƒ¼ãƒ³åˆ¥è‡ªå‹•é¸æŠ**ï¼š
```python
movement_selection = {
    'opening': 'slow_zoom_in/establishing_pan',
    'dialogue': 'static/gentle_push',
    'action': 'tracking/handheld',
    'revelation': 'dolly_in/crane_up',
    'ending': 'slow_pull_back/fade'
}
```

**ã‚«ãƒ¡ãƒ©ãƒ ãƒ¼ãƒ–ãƒ¡ãƒ³ãƒˆã¨èª¿æ•´**ï¼š

##### Staticï¼ˆå›ºå®šï¼‰
- **è‡ªå‹•é¸æŠ**: ä¼šè©±ã€è¦³å¯Ÿã€é™ã‹ãªã‚·ãƒ¼ãƒ³
- **ItoVãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ**: `static camera, no movement, stable frame`
- **èª¿æ•´ä¾‹**: ã€Œå°‘ã—å‹•ããŒæ¬²ã—ã„ã€â†’ `subtle breathing movement` è¿½åŠ 

##### Panï¼ˆãƒ‘ãƒ³ï¼‰
- **è‡ªå‹•é¸æŠ**: åºƒã„ç©ºé–“ã®ç´¹ä»‹ã€è¿½è·¡
- **ItoVãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ**: `camera pans right slowly, smooth horizontal movement`
- **èª¿æ•´ä¾‹**: 
  - é€Ÿåº¦èª¿æ•´: `fast pan` / `slow deliberate pan`
  - æ–¹å‘: `pan left to right following action`

##### Zoomï¼ˆã‚ºãƒ¼ãƒ ï¼‰
- **è‡ªå‹•é¸æŠ**: æ³¨ç›®ã®èª˜å°ã€é©šãã®è¡¨ç¾
- **ItoVãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ**: `slow zoom in, increasing tension`
- **èª¿æ•´ä¾‹**:
  - å¼·åº¦: `dramatic zoom` / `subtle zoom`
  - é€Ÿåº¦: `quick zoom` / `gradual zoom over 5 seconds`

##### Dollyï¼ˆãƒ‰ãƒªãƒ¼ï¼‰
- **è‡ªå‹•é¸æŠ**: æ²¡å…¥æ„Ÿã€ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼ã¸ã®æ¥è¿‘
- **ItoVãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ**: `dolly forward, camera moves toward subject`
- **èª¿æ•´ä¾‹**:
  - çµ„ã¿åˆã‚ã›: `dolly zoom (vertigo effect)`
  - æ–¹å‘: `dolly back revealing environment`

##### Trackingï¼ˆãƒˆãƒ©ãƒƒã‚­ãƒ³ã‚°ï¼‰
- **è‡ªå‹•é¸æŠ**: ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã®è¿½å¾“ã€ä¸¦èµ°
- **ItoVãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ**: `tracking shot following character movement`
- **èª¿æ•´ä¾‹**:
  - ã‚¹ã‚¿ã‚¤ãƒ«: `smooth steadicam tracking`
  - ä½ç½®: `parallel tracking from side`

#### 3.3.4 itov_patterns.mdï¼ˆItoVãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã®æœ€é©åŒ–ãƒ‘ã‚¿ãƒ¼ãƒ³ï¼‰

**åŸºæœ¬æ§‹é€ **ï¼š
```
[ã‚«ãƒ¡ãƒ©å‹•ä½œ] + [è¢«å†™ä½“ã®å‹•ã] + [ç¶™ç¶šæ™‚é–“] + [é›°å›²æ°—] + [ä¸€è²«æ€§æŒ‡ç¤º]
```

**ã‚·ãƒ¼ãƒ³åˆ¥æœ€é©åŒ–ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆ**ï¼š

##### ã‚ªãƒ¼ãƒ—ãƒ‹ãƒ³ã‚°ã‚·ãƒ¼ãƒ³
```
slow zoom in, subtle environmental movement, 
10 seconds, establishing mood, 
maintain first frame composition throughout
```

##### ä¼šè©±ã‚·ãƒ¼ãƒ³  
```
static camera with slight drift, 
natural gestures and facial expressions,
8 seconds, conversational pacing,
keep characters in frame
```

##### ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã‚·ãƒ¼ãƒ³
```
dynamic camera movement following action,
fast-paced character movement,
5 seconds, high energy,
maintain motion blur for speed
```

##### æ„Ÿæƒ…çš„ã‚·ãƒ¼ãƒ³
```
slow push in on face, 
subtle facial micro-expressions,
12 seconds, emotional intensity building,
maintain eye contact with camera
```

**ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆæ”¹å–„ã®ã‚³ãƒ„**ï¼š
1. **å…·ä½“çš„ãªæ™‚é–“æŒ‡å®š**: `5 seconds` ã‚ˆã‚Š `gradually over 5 seconds`
2. **å‹•ãã®è³ª**: `move` ã‚ˆã‚Š `glide smoothly` / `jerk suddenly`
3. **ä¸€è²«æ€§ã®å¼·èª¿**: å¿…ãš `maintain first frame` ç³»ã®æŒ‡ç¤ºã‚’å«ã‚ã‚‹
4. **ç‰©ç†æ³•å‰‡**: `natural physics` / `realistic motion` ã‚’è¿½åŠ 

#### 3.3.5 video_model_patterns.mdï¼ˆVeo3.1/Sora2ãƒ¢ãƒ‡ãƒ«åˆ¥æœ€é©åŒ–ï¼‰

**ãƒ¢ãƒ‡ãƒ«ç‰¹æ€§æ¯”è¼ƒ**ï¼š

| é …ç›® | Veo3.1 (Google) | Sora2 (OpenAI) |
|------|-----------------|----------------|
| **ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚¹ã‚¿ã‚¤ãƒ«** | æŠ€è¡“çš„ãƒ»æ˜ç¤ºçš„ | è‡ªç„¶è¨€èªçš„ãƒ»æå†™çš„ |
| **æ™‚é–“åˆ¶å¾¡** | ãƒ•ãƒ¬ãƒ¼ãƒ å˜ä½ã§ç´°ã‹ãæŒ‡å®šå¯èƒ½ | ã‚·ãƒ¼ãƒ³å…¨ä½“ã®æµã‚Œã‚’è¨˜è¿° |
| **ã‚«ãƒ¡ãƒ©ãƒ¯ãƒ¼ã‚¯** | æ˜ ç”»ç”¨èªã‚’æ­£ç¢ºã«ç†è§£ | ã‚ˆã‚Šç›´æ„Ÿçš„ãªè¡¨ç¾ã‚’å¥½ã‚€ |
| **ã‚¹ã‚¿ã‚¤ãƒ«æŒ‡å®š** | å…·ä½“çš„ãªæŠ€è¡“ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ | ã‚¢ãƒ¼ãƒ†ã‚£ã‚¹ãƒ†ã‚£ãƒƒã‚¯ãªè¡¨ç¾ |
| **ç‰©ç†ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³** | é«˜ç²¾åº¦ãªç‰©ç†æ¼”ç®— | è‡ªç„¶ãªå‹•ãã®è¿‘ä¼¼ |
| **å¾—æ„åˆ†é‡** | ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã€æŠ€è¡“çš„ã‚·ãƒ§ãƒƒãƒˆ | æ„Ÿæƒ…è¡¨ç¾ã€èŠ¸è¡“çš„ã‚·ãƒ¼ãƒ³ |

**Veo3.1ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆæ§‹é€ **ï¼š
```python
veo3_template = """
[Shot Settings]
Shot size: {shot_size}
Duration: {duration} seconds
FPS: {fps}
Aspect ratio: 16:9

[Camera Movement]
Type: {camera_movement}
Speed: {movement_speed}
Path: {movement_path}

[Timeline]
0-3s: {action_1}
3-6s: {action_2}
6-10s: {action_3}

[Technical Specs]
Lighting: {lighting_setup}
DOF: {depth_of_field}
Color grade: {color_grade}
"""
```

**Sora2ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆæ§‹é€ **ï¼š
```python
sora2_template = """
{opening_atmosphere}. {camera_description} 
{subject_introduction}, {action_flow}. 
{emotional_undertone}, {visual_metaphor}.
{stylistic_description}, {closing_impression}.
"""
```

**ã‚·ãƒ¼ãƒ³ã‚¿ã‚¤ãƒ—åˆ¥æ¨å¥¨ãƒ¢ãƒ‡ãƒ«**ï¼š

| ã‚·ãƒ¼ãƒ³ã‚¿ã‚¤ãƒ— | æ¨å¥¨ãƒ¢ãƒ‡ãƒ« | ç†ç”± |
|------------|-----------|------|
| é«˜é€Ÿã‚¢ã‚¯ã‚·ãƒ§ãƒ³ | Veo3.1 | ç²¾å¯†ãªæ™‚é–“åˆ¶å¾¡ã€ç‰©ç†æ¼”ç®— |
| æ„Ÿæƒ…çš„ãªç¬é–“ | Sora2 | å¾®å¦™ãªè¡¨æƒ…ã€é›°å›²æ°—è¡¨ç¾ |
| æŠ€è¡“çš„ãƒ‡ãƒ¢ | Veo3.1 | æ­£ç¢ºãªå‹•ä½œå†ç¾ |
| èŠ¸è¡“çš„è¡¨ç¾ | Sora2 | å‰µé€ çš„è§£é‡ˆã€ç¾çš„ã‚»ãƒ³ã‚¹ |
| ç¾¤é›†ã‚·ãƒ¼ãƒ³ | Veo3.1 | è¤‡é›‘ãªå‹•ãã®åˆ¶å¾¡ |
| è‡ªç„¶é¢¨æ™¯ | ä¸¡æ–¹å¯ | ãã‚Œãã‚Œã®å¼·ã¿ã‚’æ´»ç”¨ |

**ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆå¤‰æ›ä¾‹**ï¼š

```python
# å…±é€šã‚·ãƒ¼ãƒ³ï¼šæ•™å®¤ã§ã®å‹‰å¼·ã‚·ãƒ¼ãƒ³

# Veo3.1å‘ã‘ï¼ˆæŠ€è¡“çš„ï¼‰
veo3_prompt = """
Shot size: Medium shot
Duration: 10 seconds
Camera: Static tripod, eye level
Position: 2m from subject

Timeline:
0-3s: Student reading textbook
3-5s: Look up, thinking gesture
5-8s: Write notes on paper
8-10s: Return to reading

Technical:
Lighting: Natural daylight, 5600K, from left
DOF: f/2.8, background blur
Style: Photorealistic, rec709 color space
"""

# Sora2å‘ã‘ï¼ˆæå†™çš„ï¼‰
sora2_prompt = """
In a serene classroom bathed in warm afternoon sunlight,
a dedicated student sits absorbed in their studies.
The golden rays streaming through the window create
a peaceful atmosphere as they alternate between 
reading their textbook and carefully taking notes.
There's a moment of contemplation as they pause,
pen in hand, processing the information before
returning to their work with renewed focus.
The scene captures the quiet beauty of learning,
rendered in a cinematic, naturalistic style.
"""

# è‡ªå‹•å¤‰æ›é–¢æ•°ã§ã®å‡¦ç†
def auto_convert(veo3_prompt):
    # Veo3ã®æŠ€è¡“ä»•æ§˜ã‚’æŠ½å‡º
    # Sora2ã®æå†™çš„è¡¨ç¾ã«å¤‰æ›
    # æ„Ÿæƒ…ã‚„é›°å›²æ°—ã‚’è¿½åŠ 
    return sora2_prompt
```

#### 3.3.6 visual_style_extraction.mdï¼ˆã‚­ãƒ¼ãƒ“ã‚¸ãƒ¥ã‚¢ãƒ«è§£æã‚¬ã‚¤ãƒ‰ï¼‰

**ç”»åƒè§£æã§æŠ½å‡ºã™ã‚‹è¦ç´ **ï¼š

| è¦ç´  | æŠ½å‡ºå†…å®¹ | ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã¸ã®åæ˜  |
|------|---------|------------------|
| **ã‚¢ãƒ¼ãƒˆã‚¹ã‚¿ã‚¤ãƒ«** | 2D/3Dã€ã‚¢ãƒ‹ãƒ¡/ãƒªã‚¢ãƒ« | ã‚¹ã‚¿ã‚¤ãƒ«æŒ‡å®šå­ã¨ã—ã¦å…¨ã‚«ãƒƒãƒˆã«é©ç”¨ |
| **ã‚«ãƒ©ãƒ¼ãƒ‘ãƒ¬ãƒƒãƒˆ** | ä¸»è¦5è‰²ã€è‰²æ¸©åº¦ | è‰²æŒ‡å®šã€ãƒ ãƒ¼ãƒ‰è¨­å®š |
| **æ§‹å›³å‚¾å‘** | å¯¾ç§°/éå¯¾ç§°ã€é™çš„/å‹•çš„ | ã‚«ãƒ¡ãƒ©ãƒ¯ãƒ¼ã‚¯ã®åŸºèª¿ |
| **ãƒ©ã‚¤ãƒ†ã‚£ãƒ³ã‚°** | æ–¹å‘ã€å¼·åº¦ã€è‰²æ¸©åº¦ | ç…§æ˜è¨­å®šã®çµ±ä¸€ |
| **ãƒ†ã‚¯ã‚¹ãƒãƒ£** | è³ªæ„Ÿã€ãƒ‡ã‚£ãƒ†ãƒ¼ãƒ«ãƒ¬ãƒ™ãƒ« | ãƒ¬ãƒ³ãƒ€ãƒªãƒ³ã‚°å“è³ªæŒ‡å®š |

**è§£æãƒ—ãƒ­ã‚»ã‚¹**ï¼š
```python
# Gemini Vision APIã‚’ä½¿ç”¨ã—ãŸè§£æ
analysis_prompt = """
Analyze this image as a visual style reference:
1. Art style (anime, realistic, painterly, etc.)
2. Color palette (dominant colors, temperature)
3. Lighting (direction, quality, mood)
4. Composition (rule of thirds, symmetry, etc.)
5. Atmosphere and mood
6. Technical rendering style
Return structured JSON data.
"""
```

**ã‚¹ã‚¿ã‚¤ãƒ«ç¶™æ‰¿ãƒ«ãƒ¼ãƒ«**ï¼š
1. **å¼·åˆ¶ç¶™æ‰¿è¦ç´ **ï¼ˆå¿…ãšå…¨ã‚«ãƒƒãƒˆã«é©ç”¨ï¼‰
   - ã‚¢ãƒ¼ãƒˆã‚¹ã‚¿ã‚¤ãƒ«
   - åŸºæœ¬ã‚«ãƒ©ãƒ¼ãƒ‘ãƒ¬ãƒƒãƒˆ
   - ãƒ¬ãƒ³ãƒ€ãƒªãƒ³ã‚°æ‰‹æ³•

2. **æ¨å¥¨ç¶™æ‰¿è¦ç´ **ï¼ˆã‚·ãƒ¼ãƒ³ã«å¿œã˜ã¦èª¿æ•´å¯ï¼‰
   - æ§‹å›³ãƒ‘ã‚¿ãƒ¼ãƒ³
   - ãƒ©ã‚¤ãƒ†ã‚£ãƒ³ã‚°æ–¹å‘
   - é›°å›²æ°—

3. **ã‚·ãƒ¼ãƒ³å„ªå…ˆè¦ç´ **ï¼ˆã‚¹ãƒˆãƒ¼ãƒªãƒ¼ã«å¿œã˜ã¦å¤‰æ›´å¯ï¼‰
   - ã‚«ãƒ¡ãƒ©ã‚¢ãƒ³ã‚°ãƒ«
   - è¢«å†™ç•Œæ·±åº¦
   - å‹•ãã®è³ª

#### 3.3.7 music_generation_patterns.mdï¼ˆBGMç”Ÿæˆãƒ‘ã‚¿ãƒ¼ãƒ³é›†ï¼‰

**æ„Ÿæƒ…æ›²ç·šã¨BGMã®å¯¾å¿œ**ï¼š

| æ„Ÿæƒ…çŠ¶æ…‹ | æ¨å¥¨ã‚¸ãƒ£ãƒ³ãƒ« | æ¥½å™¨ç·¨æˆ | BPMç›®å®‰ |
|---------|------------|---------|---------|
| å¹³ç©ãƒ»å°å…¥ | Ambient/Classical | Piano, Strings | 60-80 |
| æœŸå¾…ãƒ»æº–å‚™ | Pop/Orchestral | + Percussion | 80-100 |
| ç·Šå¼µãƒ»ä¸å®‰ | Suspense/Electronic | Synth, Low strings | 100-120 |
| ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ | Rock/Electronic | Full band/Orchestra | 120-140 |
| æ„Ÿå‹•ãƒ»é”æˆ | Epic Orchestral | Full orchestra + Choir | 100-120 |
| ä½™éŸ»ãƒ»çµ‚çµ | Ambient/Piano | Solo piano, Strings | 60-80 |

**Sunoç”¨ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆ**ï¼š
```
[Section Name]
Genre: {musical_genre}
Mood: {emotional_descriptors}
Instruments: {instrument_list}
Tempo: {bpm} BPM, {time_signature}
Energy: {1-10}/10
Key: {musical_key}
Style: {reference_style}
Features: {unique_elements}
```

**éŸ³æ¥½ã‚»ã‚¯ã‚·ãƒ§ãƒ³åˆ†å‰²æˆ¦ç•¥**ï¼š

1. **æ„Ÿæƒ…ãƒ™ãƒ¼ã‚¹åˆ†å‰²**
   - æ„Ÿæƒ…ãŒå¤§ããå¤‰åŒ–ã™ã‚‹åœ°ç‚¹ã§åŒºåˆ‡ã‚‹
   - å„ã‚»ã‚¯ã‚·ãƒ§ãƒ³2-4ã‚«ãƒƒãƒˆç¨‹åº¦

2. **æ§‹é€ ãƒ™ãƒ¼ã‚¹åˆ†å‰²**
   - èµ·æ‰¿è»¢çµã«åˆã‚ã›ã¦3-4åˆ†å‰²
   - ã‚¤ãƒ³ãƒˆãƒ­ãƒ»ãƒ¡ã‚¤ãƒ³ãƒ»ã‚¯ãƒ©ã‚¤ãƒãƒƒã‚¯ã‚¹ãƒ»ã‚¢ã‚¦ãƒˆãƒ­

3. **æ™‚é–“ãƒ™ãƒ¼ã‚¹åˆ†å‰²**
   - 15-20ç§’ã”ã¨ã«åŒºåˆ‡ã‚‹
   - Sunoã®ç”Ÿæˆåˆ¶é™ã«åˆã‚ã›ã‚‹

**åŒæœŸãƒã‚¤ãƒ³ãƒˆã®è¨­å®š**ï¼š
```python
sync_points = {
    "hard_sync": [  # å¿…ãšåˆã‚ã›ã‚‹
        "first_frame",
        "climax_start",
        "final_frame"
    ],
    "soft_sync": [  # ç·©ã‚„ã‹ã«åˆã‚ã›ã‚‹
        "mood_changes",
        "scene_transitions"
    ],
    "accent_points": [  # ã‚¢ã‚¯ã‚»ãƒ³ãƒˆ
        "key_actions",
        "emotional_peaks"
    ]
}
```

### 3.4 ã‚¢ã‚»ãƒƒãƒˆ

#### 3.4.1 ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆ
- **storyboard_template.json**: çµµã‚³ãƒ³ãƒ†ã®æ¨™æº–æ§‹é€ 
- **character_sheet.json**: ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼å®šç¾©ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆ
- **shot_list_template.md**: ã‚·ãƒ§ãƒƒãƒˆãƒªã‚¹ãƒˆã®Markdownãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆ

#### 3.4.2 ã‚µãƒ³ãƒ—ãƒ«
- æ•™è‚²å‹•ç”»ã®çµµã‚³ãƒ³ãƒ†ä¾‹
- ãƒãƒ¼ã‚±ãƒ†ã‚£ãƒ³ã‚°å‹•ç”»ã®çµµã‚³ãƒ³ãƒ†ä¾‹
- ãƒŠãƒ©ãƒ†ã‚£ãƒ–å‹•ç”»ã®çµµã‚³ãƒ³ãƒ†ä¾‹

## 4. ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼è©³ç´°

### 4.1 åŸºæœ¬ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ï¼ˆè‡ªå‹•ç”Ÿæˆï¼‹ã‚¤ãƒ†ãƒ¬ãƒ¼ãƒ†ã‚£ãƒ–æ”¹å–„ï¼‰

```mermaid
graph TD
    A[ã‚¹ãƒˆãƒ¼ãƒªãƒ¼å…¥åŠ›] --> B[ã‚­ãƒ¼ãƒ“ã‚¸ãƒ¥ã‚¢ãƒ«è§£æ<br/>â€»ã‚ªãƒ—ã‚·ãƒ§ãƒ³]
    B --> C[AIãŒè‡ªå‹•ã§æ§‹æˆ]
    C --> D[ã‚«ãƒ¡ãƒ©ãƒ¯ãƒ¼ã‚¯è‡ªå‹•é¸æŠ]
    D --> E[ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆè‡ªå‹•ç”Ÿæˆ]
    E --> F[ç”»åƒç”Ÿæˆ]
    F --> G{çµæœç¢ºèª}
    G -->|OK| H[éŸ³æ¥½ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆç”Ÿæˆ]
    G -->|è¦ä¿®æ­£| I[ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆç·¨é›†]
    I --> J[å†ç”Ÿæˆ]
    J --> G
    H --> K[å…¨ã‚«ãƒƒãƒˆå®Œæˆ]
    K --> L[çµµã‚³ãƒ³ãƒ†ãƒ¬ãƒãƒ¼ãƒˆå‡ºåŠ›]
```

### 4.2 è©³ç´°ã‚¹ãƒ†ãƒƒãƒ—ï¼ˆè‡ªå‹•å‡¦ç†ã¨ã‚«ã‚¹ã‚¿ãƒã‚¤ã‚ºãƒã‚¤ãƒ³ãƒˆï¼‰

#### ã‚¹ãƒ†ãƒƒãƒ—0: ã‚­ãƒ¼ãƒ“ã‚¸ãƒ¥ã‚¢ãƒ«è§£æã€ã‚ªãƒ—ã‚·ãƒ§ãƒ³ã€‘
```python
# ç”»åƒã‚’å…¥åŠ›ã—ãŸå ´åˆã®ã¿å®Ÿè¡Œ
if key_visual_image:
    analyzer = ImageAnalyzer()
    visual_analysis = analyzer.analyze_key_visual(key_visual_image)
    
    # ä¸–ç•Œè¦³ã‚’æŠ½å‡º
    style_guide = analyzer.generate_style_guide(visual_analysis)
    
    print(f"æ¤œå‡ºã•ã‚ŒãŸã‚¹ã‚¿ã‚¤ãƒ«: {visual_analysis['style']}")
    print(f"ä¸»è¦è‰²å½©: {visual_analysis['colors']}")
    print(f"é›°å›²æ°—: {visual_analysis['mood']}")
```

**ç”»åƒè§£æã§å¾—ã‚‰ã‚Œã‚‹æƒ…å ±**:
- ã‚¢ãƒ¼ãƒˆã‚¹ã‚¿ã‚¤ãƒ«ï¼ˆã‚¢ãƒ‹ãƒ¡ã€ãƒªã‚¢ãƒ«ã€æ°´å½©ç”»é¢¨ãªã©ï¼‰
- ã‚«ãƒ©ãƒ¼ãƒ‘ãƒ¬ãƒƒãƒˆï¼ˆä¸»è¦5è‰²ã¨è‰²æ¸©åº¦ï¼‰
- é›°å›²æ°—ï¼ˆæ˜ã‚‹ã„ã€ãƒ€ãƒ¼ã‚¯ã€å¹»æƒ³çš„ãªã©ï¼‰
- æ§‹å›³å‚¾å‘ï¼ˆå¯¾ç§°ã€å‹•çš„ã€ãƒŸãƒ‹ãƒãƒ«ãªã©ï¼‰

#### ã‚¹ãƒ†ãƒƒãƒ—1: ã‚¹ãƒˆãƒ¼ãƒªãƒ¼åˆ†æã€å®Œå…¨è‡ªå‹•ãƒ»ã‚­ãƒ¼ãƒ“ã‚¸ãƒ¥ã‚¢ãƒ«åæ˜ ã€‘
```python
# ã‚­ãƒ¼ãƒ“ã‚¸ãƒ¥ã‚¢ãƒ«ãŒã‚ã‚‹å ´åˆã¯ä¸–ç•Œè¦³ã‚’çµ±åˆ
if style_guide:
    create_storyboard(
        "å­¦æ ¡ã®æ–‡åŒ–ç¥­ã§å‹æƒ…ã‚’æ·±ã‚ã‚‹60ç§’ã®ç‰©èª",
        key_visual_style=style_guide  # ä¸–ç•Œè¦³ã‚’ç¶™æ‰¿
    )
else:
    # å¾“æ¥é€šã‚Šãƒ†ã‚­ã‚¹ãƒˆã®ã¿ã§ç”Ÿæˆ
    create_storyboard("å­¦æ ¡ã®æ–‡åŒ–ç¥­ã§å‹æƒ…ã‚’æ·±ã‚ã‚‹60ç§’ã®ç‰©èª")
```

**AIãŒè‡ªå‹•ã§è¡Œã†ã“ã¨**ï¼š
- ã‚¸ãƒ£ãƒ³ãƒ«åˆ¤å®š â†’ é’æ˜¥/å­¦åœ’ã‚‚ã®
- æ„Ÿæƒ…æ›²ç·šåˆ†æ â†’ æœŸå¾…â†’æŒ‘æˆ¦â†’å”åŠ›â†’é”æˆ
- ã‚­ãƒ¼ãƒ¢ãƒ¼ãƒ¡ãƒ³ãƒˆç‰¹å®š â†’ æº–å‚™é–‹å§‹ã€å›°é›£ã€å”åŠ›ã€æˆåŠŸ
- ã‚«ãƒƒãƒˆæ•°æ±ºå®š â†’ 8ã‚«ãƒƒãƒˆï¼ˆ60ç§’Ã·8ï¼‰
- **ã‚­ãƒ¼ãƒ“ã‚¸ãƒ¥ã‚¢ãƒ«åæ˜ ** â†’ å…¨ã‚«ãƒƒãƒˆã«çµ±ä¸€ã‚¹ã‚¿ã‚¤ãƒ«é©ç”¨

#### ã‚¹ãƒ†ãƒƒãƒ—2: ã‚«ãƒƒãƒˆè¨­è¨ˆã€è‡ªå‹•ï¼‹ç¢ºèªå¯èƒ½ã€‘

**è‡ªå‹•ç”Ÿæˆã•ã‚Œã‚‹æ§‹æˆä¾‹**ï¼š
```
Cut 1 (10s): æœã®æ•™å®¤ - ELS - ä¸‰åˆ†å‰²æ³• - ã‚†ã£ãã‚Šã‚ºãƒ¼ãƒ ã‚¤ãƒ³
Cut 2 (8s): ä¸»äººå…¬ç´¹ä»‹ - MS - ä¸­å¿ƒæ§‹å›³ - å›ºå®š
Cut 3 (7s): ä»²é–“ã¨ã®ä¼šè©± - MS - ã‚ªãƒ¼ãƒãƒ¼ã‚·ãƒ§ãƒ«ãƒ€ãƒ¼ - ã‚«ãƒƒãƒˆåˆ‡ã‚Šæ›¿ãˆ
Cut 4 (8s): æº–å‚™ä½œæ¥­ - LS - å¯¾è§’ç·šæ§‹å›³ - ãƒ‘ãƒ³
Cut 5 (7s): ãƒˆãƒ©ãƒ–ãƒ«ç™ºç”Ÿ - CU - ä¸­å¿ƒæ§‹å›³ - ãƒãƒ³ãƒ‰ãƒ˜ãƒ«ãƒ‰
Cut 6 (8s): å”åŠ›ã—ã¦è§£æ±º - MS - ä¸‰åˆ†å‰²æ³• - ãƒˆãƒ©ãƒƒã‚­ãƒ³ã‚°
Cut 7 (7s): å®Œæˆã®ç¬é–“ - CU - ä¸­å¿ƒæ§‹å›³ - ã‚¹ãƒ­ãƒ¼ã‚ºãƒ¼ãƒ 
Cut 8 (5s): å…¨æ™¯ - ELS - é»„é‡‘æ¯” - ã‚†ã£ãã‚Šå¼•ã
```

#### ã‚¹ãƒ†ãƒƒãƒ—3: ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆç”Ÿæˆã¨ç¢ºèªã€è‡ªå‹•ï¼‹ç·¨é›†å¯èƒ½ã€‘

**åˆå›è‡ªå‹•ç”Ÿæˆãƒ—ãƒ­ãƒ³ãƒ—ãƒˆï¼ˆã‚­ãƒ¼ãƒ“ã‚¸ãƒ¥ã‚¢ãƒ«å¯¾å¿œï¼‰**ï¼š
```python
# Cut 1ã®è‡ªå‹•ç”Ÿæˆãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ
base_prompt = """
extreme wide shot, high angle, early morning classroom, 
students preparing for school festival, warm sunlight through windows,
rule of thirds composition, nostalgic mood, anime style, 16:9
"""

# ã‚­ãƒ¼ãƒ“ã‚¸ãƒ¥ã‚¢ãƒ«ãŒã‚ã‚‹å ´åˆã€ã‚¹ã‚¿ã‚¤ãƒ«ã‚’è‡ªå‹•é©ç”¨
if visual_analysis:
    image_prompt = apply_visual_reference(base_prompt, visual_analysis)
    # ä¾‹: visual_analysis['style'] = "watercolor anime"
    # ä¾‹: visual_analysis['colors'] = ["#FFE4B5", "#87CEEB", ...]
    
    image_prompt = f"""
    extreme wide shot, high angle, early morning classroom,
    students preparing for school festival, warm sunlight through windows,
    rule of thirds composition, nostalgic mood,
    {visual_analysis['style']},  # ã‚­ãƒ¼ãƒ“ã‚¸ãƒ¥ã‚¢ãƒ«ã®ã‚¹ã‚¿ã‚¤ãƒ«
    color palette: {', '.join(visual_analysis['colors'][:3])},  # ä¸»è¦è‰²
    matching visual reference style,  # ä¸€è²«æ€§ã®æŒ‡ç¤º
    16:9
    """

# çµæœã‚’è¦‹ã¦èª¿æ•´ã—ãŸã„å ´åˆ
adjusted_prompt = """
extreme wide shot, eye level, [ã‚«ãƒ¡ãƒ©ã‚¢ãƒ³ã‚°ãƒ«ã‚’å¤‰æ›´]
busy classroom with colorful decorations, [è©³ç´°ã‚’è¿½åŠ ]
students in school uniforms working together,
golden hour lighting, [ç…§æ˜ã‚’å¤‰æ›´]
rule of thirds composition, energetic mood, 
maintain key visual style consistency,  # ã‚­ãƒ¼ãƒ“ã‚¸ãƒ¥ã‚¢ãƒ«ã¨ã®ä¸€è²«æ€§ç¶­æŒ
anime style, 16:9
"""
```

#### ã‚¹ãƒ†ãƒƒãƒ—4: ã‚¤ãƒ†ãƒ¬ãƒ¼ãƒ†ã‚£ãƒ–ãªç”»åƒç”Ÿæˆ

```python
# 1. åˆå›ç”Ÿæˆ
result = generate_image(cut_1_prompt)
# â†’ output/frames/cut_01_v1.jpg

# 2. ç¢ºèªã—ã¦ä¿®æ­£ãŒå¿…è¦ãªå ´åˆ
if "ã‚‚ã£ã¨æ˜ã‚‹ãã€ç”Ÿå¾’ã‚’å¢—ã‚„ã—ãŸã„":
    cut_1_prompt_v2 = modify_prompt(
        original=cut_1_prompt,
        changes="brighter lighting, more students, festive atmosphere"
    )
    result = generate_image(cut_1_prompt_v2)
    # â†’ output/frames/cut_01_v2.jpg

# 3. æº€è¶³ã—ãŸã‚‰æ¬¡ã®ã‚«ãƒƒãƒˆã¸
confirm_and_proceed()
```

#### ã‚¹ãƒ†ãƒƒãƒ—5: ItoVãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã®èª¿æ•´

**è‡ªå‹•ç”Ÿæˆã•ã‚Œã‚‹ItoVãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ**ï¼š
```python
video_prompt_auto = """
slow zoom in, bustling student activity,
10 seconds, establishing mood,
maintain first frame composition
"""

# ã‚«ãƒ¡ãƒ©ãƒ¯ãƒ¼ã‚¯ã‚’èª¿æ•´ã—ãŸã„å ´åˆ
video_prompt_custom = """
slow pan right then zoom in, [ã‚«ãƒ¡ãƒ©å‹•ä½œã‚’å¤‰æ›´]
students moving naturally, papers rustling,
10 seconds, building excitement,
maintain character positions
"""
```

#### ã‚¹ãƒ†ãƒƒãƒ—6: æœ€çµ‚å‡ºåŠ›ã¨å†èª¿æ•´ã‚ªãƒ—ã‚·ãƒ§ãƒ³

**ç”Ÿæˆã•ã‚Œã‚‹æˆæœç‰©**ï¼š
1. **storyboard.json** - å…¨ãƒ‡ãƒ¼ã‚¿ï¼ˆãƒ—ãƒ­ãƒ³ãƒ—ãƒˆå±¥æ­´å«ã‚€ï¼‰
2. **storyboard_report.md** - ãƒ“ã‚¸ãƒ¥ã‚¢ãƒ«ãƒ¬ãƒãƒ¼ãƒˆ
3. **frames/** - ç”Ÿæˆã•ã‚ŒãŸç”»åƒï¼ˆãƒãƒ¼ã‚¸ãƒ§ãƒ³ç®¡ç†ï¼‰
4. **prompts_history.json** - ä¿®æ­£å±¥æ­´ï¼ˆå­¦ç¿’ç”¨ï¼‰

#### ã‚¹ãƒ†ãƒƒãƒ—7: BGMãƒ—ãƒ­ãƒ³ãƒ—ãƒˆç”Ÿæˆã€è‡ªå‹•ã€‘

```python
# çµµã‚³ãƒ³ãƒ†å®Œæˆå¾Œã€BGMãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’è‡ªå‹•ç”Ÿæˆ
music_generator = MusicPromptGenerator()

# æ„Ÿæƒ…æ›²ç·šã‚’åˆ†æ
emotional_arc = music_generator.analyze_emotional_arc(storyboard)

# éŸ³æ¥½ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã‚’å®šç¾©
music_sections = music_generator.create_music_sections(storyboard)

# Sunoç”¨ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆç”Ÿæˆ
suno_prompts = music_generator.generate_suno_prompts(
    music_sections,
    storyboard
)
```

**ç”Ÿæˆã•ã‚Œã‚‹BGMæ§‹æˆä¾‹**ï¼š
```python
{
    "section_1": {
        "cuts": [1, 2, 3],  # ã‚«ãƒƒãƒˆ1-3
        "duration": 25,  # ç§’
        "prompt": "[Hopeful intro] Cinematic orchestral, Energy: 4/10, 
                   Instruments: piano, strings, soft percussion,
                   Mood: anticipation building, morning atmosphere",
        "bpm": 80
    },
    "section_2": {
        "cuts": [4, 5, 6],  # ã‚«ãƒƒãƒˆ4-6
        "duration": 20,
        "prompt": "[Energetic main] Uplifting pop-rock, Energy: 7/10,
                   Instruments: guitar, drums, bass, synth,
                   Mood: excitement, teamwork, positive energy",
        "bpm": 120
    },
    "section_3": {
        "cuts": [7, 8],  # ã‚«ãƒƒãƒˆ7-8
        "duration": 15,
        "prompt": "[Triumphant outro] Epic orchestral finale, Energy: 9/10,
                   Instruments: full orchestra, choir, timpani,
                   Mood: victory, celebration, emotional peak",
        "bpm": 140
    }
}
```

**éŸ³æ¥½åŒæœŸã‚¿ã‚¤ãƒŸãƒ³ã‚°ã‚·ãƒ¼ãƒˆ**ï¼š
```markdown
| æ™‚é–“ | ã‚«ãƒƒãƒˆ | éŸ³æ¥½ã‚»ã‚¯ã‚·ãƒ§ãƒ³ | ã‚­ãƒ¥ãƒ¼ãƒã‚¤ãƒ³ãƒˆ |
|------|--------|--------------|---------------|
| 0:00 | Cut 1 | Section 1é–‹å§‹ | é™ã‹ãªãƒ”ã‚¢ãƒå°å…¥ |
| 0:10 | Cut 2 | Section 1ç¶™ç¶š | ã‚¹ãƒˆãƒªãƒ³ã‚°ã‚¹è¿½åŠ  |
| 0:18 | Cut 3 | Section 1ç¶™ç¶š | ãƒ“ãƒ«ãƒ‰ã‚¢ãƒƒãƒ— |
| 0:25 | Cut 4 | Section 2é–‹å§‹ | ãƒ‰ãƒ©ãƒ ã‚¤ãƒ³ |
| 0:33 | Cut 5 | Section 2ç¶™ç¶š | ãƒ¡ã‚¤ãƒ³ãƒ¡ãƒ­ãƒ‡ã‚£ |
| 0:40 | Cut 6 | Section 2ç¶™ç¶š | ãƒ–ãƒªãƒƒã‚¸ |
| 0:45 | Cut 7 | Section 3é–‹å§‹ | ã‚¯ãƒ©ã‚¤ãƒãƒƒã‚¯ã‚¹ |
| 0:52 | Cut 8 | Section 3ç¶™ç¶š | ãƒ•ã‚£ãƒŠãƒ¼ãƒ¬ |
```

### 4.3 ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆä¿®æ­£ã‚¬ã‚¤ãƒ‰

#### ã‚ˆãã‚ã‚‹ä¿®æ­£ãƒ‘ã‚¿ãƒ¼ãƒ³ã¨è§£æ±ºæ–¹æ³•

| å•é¡Œ | ä¿®æ­£æ–¹æ³• | ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆå¤‰æ›´ä¾‹ |
|------|---------|----------------|
| æš—ã™ãã‚‹ | ç…§æ˜ã‚’è¿½åŠ  | + `bright lighting, well-lit` |
| äººãŒå°‘ãªã„ | äººæ•°æŒ‡å®š | + `crowded, many students` |
| æ§‹å›³ãŒåã‚‹ | æ§‹å›³ã‚’æ˜ç¤º | + `perfectly centered` |
| å‹•ããŒç¡¬ã„ | è‡ªç„¶ãªå‹•ã | + `natural movement, casual poses` |
| ã‚¹ã‚¿ã‚¤ãƒ«ãŒé•ã† | ã‚¹ã‚¿ã‚¤ãƒ«å¼·èª¿ | + `anime style, cel-shaded` |

#### ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆæ”¹å–„ã®ãƒ™ã‚¹ãƒˆãƒ—ãƒ©ã‚¯ãƒ†ã‚£ã‚¹

1. **è¿½åŠ ã‚ˆã‚Šç½®æ›**
   - âŒ æ‚ªã„ä¾‹: å…ƒã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ + æ–°ã—ã„è¦ç´ ã‚’ã©ã‚“ã©ã‚“è¿½åŠ 
   - âœ… è‰¯ã„ä¾‹: å•é¡Œã®ã‚ã‚‹éƒ¨åˆ†ã‚’ç‰¹å®šã—ã¦ç½®æ›

2. **å…·ä½“çš„ãªæŒ‡ç¤º**
   - âŒ æ‚ªã„ä¾‹: `better lighting`
   - âœ… è‰¯ã„ä¾‹: `soft morning sunlight from left window`

3. **å„ªå…ˆé †ä½ã‚’æ„è­˜**
   - ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã®å‰åŠã«ã‚ˆã‚Šæ³¨æ„ãŒæ‰•ã‚ã‚Œã‚‹
   - é‡è¦ãªè¦ç´ ã¯å‰ã«é…ç½®

4. **ãƒã‚¬ãƒ†ã‚£ãƒ–ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã®æ´»ç”¨**
   - é¿ã‘ãŸã„è¦ç´ ã‚’æ˜ç¤º: `no shadows, no blur`

### 4.4 ãƒãƒƒãƒå‡¦ç†ã¨ãƒãƒ¼ã‚¸ãƒ§ãƒ³ç®¡ç†

#### è¤‡æ•°ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã®ç®¡ç†

```python
# å„ã‚«ãƒƒãƒˆã§è¤‡æ•°ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã‚’ç”Ÿæˆã—ã¦é¸æŠ
for cut in storyboard.cuts:
    versions = []
    for i in range(3):  # 3ãƒãƒ¼ã‚¸ãƒ§ãƒ³ç”Ÿæˆ
        variant_prompt = add_variation(cut.image_prompt, seed=i)
        image = generate_image(variant_prompt)
        versions.append(image)
    
    # ãƒ™ã‚¹ãƒˆã‚’é¸æŠ
    best_version = select_best(versions)
    cut.final_image = best_version
```

#### å­¦ç¿’ç”¨ãƒ‡ãƒ¼ã‚¿ã®è“„ç©

```python
# ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆæ”¹å–„å±¥æ­´ã‚’ä¿å­˜
improvement_log = {
    "cut_1": {
        "original": "initial prompt...",
        "iterations": [
            {"version": 1, "change": "added lighting", "result": "better"},
            {"version": 2, "change": "changed angle", "result": "perfect"}
        ],
        "final": "final prompt...",
        "lessons": "High angle worked better than eye level"
    }
}
```

## 5. APIä»•æ§˜

### 5.1 Gemini APIè¨­å®š

```python
# ç’°å¢ƒå¤‰æ•°
GEMINI_API_KEY = "your-api-key"

# APIè¨­å®š
MODEL_IMAGE = "imagen-3.0-generate-002"
MODEL_TEXT = "gemini-2.0-flash-exp"

# åˆ¶é™äº‹é …
MAX_IMAGES_PER_BATCH = 4
RATE_LIMIT = 60  # requests per minute
IMAGE_COST = 0.03  # USD per image
```

### 5.2 ä¸»è¦ãƒ‡ãƒ¼ã‚¿æ§‹é€ 

```python
@dataclass
class StoryboardData:
    title: str
    duration: int
    num_cuts: int
    cuts: List[CutData]
    characters: List[CharacterData]
    style_guide: StyleGuide
    key_visual_analysis: Optional[Dict]  # è¿½åŠ ï¼šã‚­ãƒ¼ãƒ“ã‚¸ãƒ¥ã‚¢ãƒ«è§£æçµæœ
    music_sections: Optional[List[MusicSection]]  # è¿½åŠ ï¼šBGMã‚»ã‚¯ã‚·ãƒ§ãƒ³

@dataclass
class CutData:
    cut_number: int
    duration: int
    scene_description: str
    action: str
    composition: str
    camera_angle: str
    camera_movement: str
    lighting: str
    mood: str
    image_prompt: str
    video_prompt: str
    generated_image_path: Optional[str]
    style_modifiers: Optional[List[str]]  # è¿½åŠ ï¼šã‚­ãƒ¼ãƒ“ã‚¸ãƒ¥ã‚¢ãƒ«ã‹ã‚‰ã®ã‚¹ã‚¿ã‚¤ãƒ«
    color_palette: Optional[Dict]  # è¿½åŠ ï¼šè‰²å½©æŒ‡å®š

@dataclass
class MusicSection:
    section_id: int
    cuts: List[int]
    duration: int
    suno_prompt: str
    style_tags: List[str]
    bpm: int
    energy_level: int
    transition_type: Optional[str]
```

### 5.3 çµ±åˆãƒ¡ã‚¤ãƒ³ã‚¹ã‚¯ãƒªãƒ—ãƒˆã®æ›´æ–°ä¾‹

```python
#!/usr/bin/env python3
"""
AI Video Storyboard Generator with Visual Reference and Music Generation
Enhanced version with key visual analysis and BGM prompt generation
"""

from ai_video_storyboard import (
    StoryboardGenerator,
    ImageAnalyzer,
    MusicPromptGenerator,
    VideoModelOptimizer
)

def create_enhanced_storyboard(
    story_description: str,
    key_visual_path: Optional[str] = None,
    generate_music: bool = True,
    video_model: str = "auto",
    output_dir: str = "output"
):
    """
    æ‹¡å¼µç‰ˆçµµã‚³ãƒ³ãƒ†ç”Ÿæˆï¼ˆã‚­ãƒ¼ãƒ“ã‚¸ãƒ¥ã‚¢ãƒ«ï¼‹BGMå¯¾å¿œï¼‰
    
    Args:
        story_description: ã‚¹ãƒˆãƒ¼ãƒªãƒ¼ã®èª¬æ˜
        key_visual_path: ã‚­ãƒ¼ãƒ“ã‚¸ãƒ¥ã‚¢ãƒ«ç”»åƒã®ãƒ‘ã‚¹ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
        generate_music: BGMãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ç”Ÿæˆã™ã‚‹ã‹
        video_model: ãƒ“ãƒ‡ã‚ªç”Ÿæˆãƒ¢ãƒ‡ãƒ«ï¼ˆveo3/sora2/autoï¼‰
        output_dir: å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
    """
    
    # Step 1: ã‚­ãƒ¼ãƒ“ã‚¸ãƒ¥ã‚¢ãƒ«è§£æï¼ˆã‚ã‚Œã°ï¼‰
    style_guide = None
    visual_analysis = None
    
    if key_visual_path:
        print("ğŸ“¸ ã‚­ãƒ¼ãƒ“ã‚¸ãƒ¥ã‚¢ãƒ«ã‚’è§£æä¸­...")
        analyzer = ImageAnalyzer()
        visual_analysis = analyzer.analyze_key_visual(key_visual_path)
        style_guide = analyzer.generate_style_guide(visual_analysis)
        
        print(f"  æ¤œå‡ºã•ã‚ŒãŸã‚¹ã‚¿ã‚¤ãƒ«: {visual_analysis['style']}")
        print(f"  ä¸»è¦è‰²å½©: {visual_analysis['colors'][:3]}")
        print(f"  é›°å›²æ°—: {visual_analysis['mood']}")
    
    # Step 2: çµµã‚³ãƒ³ãƒ†ç”Ÿæˆ
    print("\nğŸ“ çµµã‚³ãƒ³ãƒ†ã‚’ç”Ÿæˆä¸­...")
    generator = StoryboardGenerator()
    
    storyboard = generator.generate_complete_storyboard(
        story_description,
        key_visual_style=style_guide,
        config={
            "video_model": video_model,
            "visual_analysis": visual_analysis
        }
    )
    
    print(f"  {storyboard.num_cuts}ã‚«ãƒƒãƒˆã®çµµã‚³ãƒ³ãƒ†ã‚’ç”Ÿæˆã—ã¾ã—ãŸ")
    
    # Step 3: ãƒ¢ãƒ‡ãƒ«åˆ¥æœ€é©åŒ–ï¼ˆVeo3.1/Sora2ï¼‰
    if video_model == "auto":
        print("\nğŸ¬ ãƒ“ãƒ‡ã‚ªãƒ¢ãƒ‡ãƒ«åˆ¥ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ç”Ÿæˆä¸­...")
        optimizer = VideoModelOptimizer(target_model="auto")
        
        for cut in storyboard.cuts:
            prompts = optimizer.generate_optimized_prompt(cut.__dict__)
            cut.veo3_prompt = prompts.get("veo3")
            cut.sora2_prompt = prompts.get("sora2")
            
            # æ¨å¥¨ãƒ¢ãƒ‡ãƒ«ã‚’åˆ¤å®š
            recommendation = optimizer.recommend_model(cut.__dict__)
            cut.recommended_model = recommendation["recommended_model"]
    
    # Step 4: BGMãƒ—ãƒ­ãƒ³ãƒ—ãƒˆç”Ÿæˆ
    music_data = None
    if generate_music:
        print("\nğŸµ BGMãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ç”Ÿæˆä¸­...")
        music_gen = MusicPromptGenerator()
        
        # æ„Ÿæƒ…æ›²ç·šåˆ†æ
        emotional_arc = music_gen.analyze_emotional_arc(storyboard)
        
        # éŸ³æ¥½ã‚»ã‚¯ã‚·ãƒ§ãƒ³ä½œæˆ
        music_sections = music_gen.create_music_sections(storyboard)
        print(f"  {len(music_sections)}ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã«åˆ†å‰²")
        
        # Sunoãƒ—ãƒ­ãƒ³ãƒ—ãƒˆç”Ÿæˆ
        suno_prompts = music_gen.generate_suno_prompts(
            music_sections,
            storyboard
        )
        
        # ã‚¿ã‚¤ãƒŸãƒ³ã‚°ã‚·ãƒ¼ãƒˆç”Ÿæˆ
        timing_sheet = music_gen.generate_timing_sheet(
            suno_prompts,
            storyboard
        )
        
        music_data = {
            "emotional_arc": emotional_arc,
            "sections": music_sections,
            "suno_prompts": suno_prompts,
            "timing_sheet": timing_sheet
        }
        
        # çµµã‚³ãƒ³ãƒ†ã«éŸ³æ¥½æƒ…å ±ã‚’è¿½åŠ 
        storyboard.music_sections = music_sections
    
    # Step 5: ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ
    print("\nğŸ“Š ãƒ¬ãƒãƒ¼ãƒˆã‚’ç”Ÿæˆä¸­...")
    
    # çµ±åˆãƒ¬ãƒãƒ¼ãƒˆä½œæˆ
    create_enhanced_report(
        storyboard,
        visual_analysis,
        music_data,
        output_dir
    )
    
    print(f"\nâœ… å®Œæˆï¼")
    print(f"ğŸ“ å‡ºåŠ›å…ˆ: {output_dir}/")
    print(f"  ğŸ“„ storyboard_enhanced.json")
    print(f"  ğŸ“„ storyboard_report.md")
    print(f"  ğŸµ music_prompts.json")
    print(f"  ğŸ–¼ï¸ frames/")
    
    return storyboard


def create_enhanced_report(storyboard, visual_analysis, music_data, output_dir):
    """
    æ‹¡å¼µç‰ˆãƒ¬ãƒãƒ¼ãƒˆã®ç”Ÿæˆ
    """
    report = []
    
    # ãƒ˜ãƒƒãƒ€ãƒ¼
    report.append(f"# {storyboard.title}")
    report.append("")
    
    # ã‚­ãƒ¼ãƒ“ã‚¸ãƒ¥ã‚¢ãƒ«æƒ…å ±ï¼ˆã‚ã‚Œã°ï¼‰
    if visual_analysis:
        report.append("## ğŸ¨ ãƒ“ã‚¸ãƒ¥ã‚¢ãƒ«ã‚¹ã‚¿ã‚¤ãƒ«ã‚¬ã‚¤ãƒ‰")
        report.append(f"- **ã‚¢ãƒ¼ãƒˆã‚¹ã‚¿ã‚¤ãƒ«**: {visual_analysis['style']}")
        report.append(f"- **ã‚«ãƒ©ãƒ¼ãƒ‘ãƒ¬ãƒƒãƒˆ**: {visual_analysis['colors']}")
        report.append(f"- **é›°å›²æ°—**: {visual_analysis['mood']}")
        report.append("")
    
    # çµµã‚³ãƒ³ãƒ†
    report.append("## ğŸ¬ çµµã‚³ãƒ³ãƒ†")
    for cut in storyboard.cuts:
        report.append(f"\n### Cut {cut.cut_number} ({cut.duration}ç§’)")
        if cut.generated_image_path:
            report.append(f"![Cut {cut.cut_number}]({cut.generated_image_path})")
        report.append(f"**ã‚·ãƒ¼ãƒ³**: {cut.scene_description}")
        report.append(f"**æ¨å¥¨ãƒ¢ãƒ‡ãƒ«**: {getattr(cut, 'recommended_model', 'N/A')}")
        report.append("")
    
    # BGMæƒ…å ±ï¼ˆã‚ã‚Œã°ï¼‰
    if music_data:
        report.append("## ğŸµ BGMãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ")
        for section in music_data['suno_prompts']:
            report.append(f"\n### Section {section['section_id']}")
            report.append(f"**ã‚«ãƒƒãƒˆ**: {section['cuts']}")
            report.append(f"**é•·ã•**: {section['duration']}ç§’")
            report.append(f"**BPM**: {section['bpm_suggestion']}")
            report.append("```")
            report.append(section['prompt'])
            report.append("```")
    
    # ãƒ•ã‚¡ã‚¤ãƒ«ä¿å­˜
    with open(f"{output_dir}/storyboard_report.md", "w", encoding="utf-8") as f:
        f.write("\n".join(report))


# ä½¿ç”¨ä¾‹
if __name__ == "__main__":
    import argparse
    
    parser = argparse.ArgumentParser(
        description="AI Video Storyboard Generator with Visual and Music"
    )
    parser.add_argument("story", help="Story description")
    parser.add_argument("--key-visual", help="Path to key visual image")
    parser.add_argument("--no-music", action="store_true", help="Skip BGM generation")
    parser.add_argument("--model", default="auto", choices=["veo3", "sora2", "auto"])
    parser.add_argument("--output", default="output", help="Output directory")
    
    args = parser.parse_args()
    
    storyboard = create_enhanced_storyboard(
        story_description=args.story,
        key_visual_path=args.key_visual,
        generate_music=not args.no_music,
        video_model=args.model,
        output_dir=args.output
    )
```

## 6. ä½¿ç”¨ä¾‹

### 6.1 åŸºæœ¬çš„ãªä½¿ç”¨ï¼ˆå®Œå…¨è‡ªå‹•ï¼‰

```bash
# ç’°å¢ƒå¤‰æ•°è¨­å®š
export GEMINI_API_KEY='your-key'

# 1è¡Œã§çµµã‚³ãƒ³ãƒ†ç”Ÿæˆï¼ˆAIãŒå…¨ã¦è‡ªå‹•åˆ¤æ–­ï¼‰
python scripts/generate_storyboard.py \
  "é«˜æ ¡ã®æ–‡åŒ–ç¥­æº–å‚™ã‚’é¡Œæã«ã—ãŸ60ç§’ã®é’æ˜¥å‹•ç”»"

# ã‚­ãƒ¼ãƒ“ã‚¸ãƒ¥ã‚¢ãƒ«ã‚ã‚Šã®å ´åˆ
python scripts/generate_storyboard.py \
  "é«˜æ ¡ã®æ–‡åŒ–ç¥­æº–å‚™ã‚’é¡Œæã«ã—ãŸ60ç§’ã®é’æ˜¥å‹•ç”»" \
  --key-visual "path/to/reference_image.jpg"

# å‡ºåŠ›
# âœ… AIãŒè‡ªå‹•ã§ä»¥ä¸‹ã‚’æ±ºå®šï¼š
# - 8ã‚«ãƒƒãƒˆæ§‹æˆ
# - å„ã‚«ãƒƒãƒˆã®ã‚«ãƒ¡ãƒ©ãƒ¯ãƒ¼ã‚¯
# - æ§‹å›³ï¼ˆä¸‰åˆ†å‰²æ³•ã€ä¸­å¿ƒæ§‹å›³ãªã©ï¼‰
# - ã‚«ãƒ¡ãƒ©ãƒ ãƒ¼ãƒ–ãƒ¡ãƒ³ãƒˆ
# - ç…§æ˜ã¨ãƒ ãƒ¼ãƒ‰
# - ã‚­ãƒ¼ãƒ“ã‚¸ãƒ¥ã‚¢ãƒ«ã‹ã‚‰ã®ã‚¹ã‚¿ã‚¤ãƒ«ç¶™æ‰¿ï¼ˆç”»åƒå…¥åŠ›æ™‚ï¼‰
# - BGMæ§‹æˆã¨Sunoãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ
```

### 6.1.1 ã‚­ãƒ¼ãƒ“ã‚¸ãƒ¥ã‚¢ãƒ«ã‚’ä½¿ç”¨ã—ãŸä¸–ç•Œè¦³çµ±ä¸€

```python
from ai_video_storyboard import StoryboardGenerator, ImageAnalyzer

# ã‚­ãƒ¼ãƒ“ã‚¸ãƒ¥ã‚¢ãƒ«ã®è§£æ
analyzer = ImageAnalyzer()
visual_ref = analyzer.analyze_key_visual("concept_art.jpg")

print(f"æ¤œå‡ºã•ã‚ŒãŸã‚¹ã‚¿ã‚¤ãƒ«: {visual_ref['style']}")
# å‡ºåŠ›: "watercolor anime with soft edges"

print(f"ã‚«ãƒ©ãƒ¼ãƒ‘ãƒ¬ãƒƒãƒˆ: {visual_ref['colors']}")
# å‡ºåŠ›: ["#FFE4B5", "#87CEEB", "#98FB98", "#FFB6C1", "#DDA0DD"]

# ã‚¹ã‚¿ã‚¤ãƒ«ã‚’å…¨ã‚«ãƒƒãƒˆã«é©ç”¨
generator = StoryboardGenerator()
storyboard = generator.generate_complete_storyboard(
    story="é­”æ³•å­¦æ ¡ã®ä¸€æ—¥",
    key_visual=visual_ref,
    config={
        "enforce_visual_consistency": True,
        "style_weight": 0.8  # 80%ã‚­ãƒ¼ãƒ“ã‚¸ãƒ¥ã‚¢ãƒ«æº–æ‹ 
    }
)

# ç”Ÿæˆã•ã‚Œã‚‹å„ã‚«ãƒƒãƒˆã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã«è‡ªå‹•çš„ã«å«ã¾ã‚Œã‚‹è¦ç´ ï¼š
# - "watercolor anime style"
# - "soft pastel colors (#FFE4B5, #87CEEB, #98FB98)"
# - "dreamy atmosphere matching reference"
```

### 6.1.2 BGMç”Ÿæˆãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã®æ´»ç”¨

```python
from ai_video_storyboard import MusicPromptGenerator

# ã‚¹ãƒˆãƒ¼ãƒªãƒ¼ãƒœãƒ¼ãƒ‰å®Œæˆå¾Œ
music_gen = MusicPromptGenerator()
music_sections = music_gen.analyze_and_generate(storyboard)

print("=== ç”Ÿæˆã•ã‚ŒãŸBGMæ§‹æˆ ===")
for section in music_sections:
    print(f"\nã€ã‚»ã‚¯ã‚·ãƒ§ãƒ³ {section['id']}ã€‘")
    print(f"ã‚«ãƒƒãƒˆ: {section['cuts']}")
    print(f"æ™‚é–“: {section['duration']}ç§’")
    print(f"Sunoãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ: {section['suno_prompt']}")

# å‡ºåŠ›ä¾‹ï¼š
"""
=== ç”Ÿæˆã•ã‚ŒãŸBGMæ§‹æˆ ===

ã€ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 1ã€‘
ã‚«ãƒƒãƒˆ: 1-3
æ™‚é–“: 25ç§’
Sunoãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ: [Gentle Morning] Soft orchestral intro, 75bpm, 
peaceful and hopeful, piano lead with string accompaniment, 
building anticipation, school morning atmosphere

ã€ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 2ã€‘
ã‚«ãƒƒãƒˆ: 4-6
æ™‚é–“: 23ç§’
Sunoãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ: [Energetic Preparation] Upbeat J-pop, 128bpm,
cheerful and busy, full band with emphasis on drums and guitar,
teamwork energy, festival excitement

ã€ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 3ã€‘
ã‚«ãƒƒãƒˆ: 7-8
æ™‚é–“: 12ç§’
Sunoãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ: [Triumphant Finale] Epic orchestral climax, 90bpm,
emotional and uplifting, full orchestra with choir elements,
achievement and friendship theme, grand ending
"""
```

### 6.2 ã‚¤ãƒ†ãƒ¬ãƒ¼ãƒ†ã‚£ãƒ–ãªæ”¹å–„ãƒ•ãƒ­ãƒ¼

```python
from ai_video_storyboard import StoryboardGenerator

generator = StoryboardGenerator()

# 1. åˆå›ç”Ÿæˆï¼ˆå®Œå…¨è‡ªå‹•ï¼‰
storyboard = generator.generate_complete_storyboard(
    "æ•™è‚²å‹•ç”»ï¼šæ°´ã®å¾ªç’°ã‚’èª¬æ˜ã™ã‚‹60ç§’ã®ã‚¢ãƒ‹ãƒ¡ãƒ¼ã‚·ãƒ§ãƒ³"
)

# 2. çµæœç¢ºèª
print(f"ç”Ÿæˆã•ã‚ŒãŸã‚«ãƒƒãƒˆæ•°: {storyboard.num_cuts}")
for cut in storyboard.cuts:
    print(f"Cut {cut.cut_number}: {cut.scene_description}")
    print(f"  ã‚«ãƒ¡ãƒ©: {cut.camera_angle}, æ§‹å›³: {cut.composition}")

# 3. ç‰¹å®šã®ã‚«ãƒƒãƒˆã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ä¿®æ­£
if "Cut 3ã®é›²ã®è¡¨ç¾ãŒç‰©è¶³ã‚Šãªã„":
    # å…ƒã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ç¢ºèª
    original = storyboard.cuts[2].image_prompt
    print(f"å…ƒã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ: {original}")
    
    # ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ä¿®æ­£
    storyboard.cuts[2].image_prompt = """
    extreme wide shot, dramatic clouds forming, 
    time-lapse effect, volumetric lighting,
    epic scale, detailed cumulus clouds,
    rule of thirds, cinematic, 16:9
    """
    
    # å†ç”Ÿæˆ
    new_image = generator.generate_single_image(
        storyboard.cuts[2].image_prompt,
        cut_number=3
    )

# 4. ã‚«ãƒ¡ãƒ©ãƒ¯ãƒ¼ã‚¯ã®èª¿æ•´
if "Cut 5ã®ã‚«ãƒ¡ãƒ©ãŒé™çš„ã™ãã‚‹":
    # ItoVãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ä¿®æ­£
    storyboard.cuts[4].video_prompt = """
    dynamic camera movement, slow dolly in with slight rotation,
    water droplets falling, 8 seconds,
    building tension, maintain focus on water cycle
    """
```

### 6.3 ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆä¿®æ­£ã®å®Ÿä¾‹

#### ä¾‹1: ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼ãŒå°‘ãªã„å•é¡Œ

```python
# åˆå›ç”Ÿæˆçµæœ
original_prompt = "classroom scene, students preparing"
# çµæœ: ç”Ÿå¾’ãŒ2-3äººã—ã‹ã„ãªã„

# ä¿®æ­£ç‰ˆ
improved_prompt = """
busy classroom scene, 15-20 students actively preparing,
diverse group working on different tasks,
some painting, some carrying props, some discussing,
lively atmosphere, movement throughout frame
"""
# çµæœ: è³‘ã‚„ã‹ãªæ•™å®¤ã‚·ãƒ¼ãƒ³
```

#### ä¾‹2: ç…§æ˜ãŒæš—ã„å•é¡Œ

```python
# åˆå›ç”Ÿæˆçµæœ  
original_prompt = "morning classroom, natural lighting"
# çµæœ: å…¨ä½“çš„ã«æš—ã„

# ä¿®æ­£ç‰ˆ
improved_prompt = """
bright morning classroom, golden hour sunlight streaming through windows,
well-lit interior, soft shadows, warm color temperature,
optimistic mood, high key lighting
"""
# çµæœ: æ˜ã‚‹ãæ¸©ã‹ã„é›°å›²æ°—
```

#### ä¾‹3: æ§‹å›³ãŒå˜èª¿ãªå•é¡Œ

```python
# åˆå›ç”Ÿæˆçµæœ
original_prompt = "students in classroom, centered composition"
# çµæœ: å…¨å“¡ãŒä¸­å¤®ã«å›ºã¾ã£ã¦ã„ã‚‹

# ä¿®æ­£ç‰ˆ
improved_prompt = """
students distributed across frame using rule of thirds,
foreground student on left third, background group on right,
depth layers with students at different distances,
diagonal composition lines created by desk arrangement
"""
# çµæœ: å¥¥è¡Œãã®ã‚ã‚‹ãƒ€ã‚¤ãƒŠãƒŸãƒƒã‚¯ãªæ§‹å›³
```

### 6.4 ãƒãƒƒãƒå‡¦ç†ã§ã®å“è³ªç®¡ç†

```python
# è¤‡æ•°ãƒãƒªã‚¨ãƒ¼ã‚·ãƒ§ãƒ³ã‚’ç”Ÿæˆã—ã¦æœ€è‰¯ã‚’é¸æŠ
def generate_with_variations(story, quality_mode="high"):
    
    if quality_mode == "high":
        # å„ã‚«ãƒƒãƒˆã§3ãƒãƒªã‚¨ãƒ¼ã‚·ãƒ§ãƒ³ç”Ÿæˆ
        config = {
            "variations_per_cut": 3,
            "auto_select_best": True,
            "selection_criteria": ["composition", "clarity", "mood"]
        }
    else:
        # é€šå¸¸ã¯1ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã®ã¿
        config = {"variations_per_cut": 1}
    
    results = []
    for i in range(config["variations_per_cut"]):
        storyboard = generator.generate_complete_storyboard(
            story, 
            config={**config, "seed": i}
        )
        results.append(storyboard)
    
    # è‡ªå‹•ã¾ãŸã¯ãƒãƒ‹ãƒ¥ã‚¢ãƒ«ã§æœ€è‰¯ã‚’é¸æŠ
    if config.get("auto_select_best"):
        best = auto_select_best_storyboard(results)
    else:
        best = manual_selection_ui(results)
    
    return best
```

### 6.5 å­¦ç¿’ãƒ¢ãƒ¼ãƒ‰ï¼ˆãƒ—ãƒ­ãƒ³ãƒ—ãƒˆæ”¹å–„ã®è¨˜éŒ²ï¼‰

```python
# ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆæ”¹å–„ã‚’è¨˜éŒ²ã—ã¦å­¦ç¿’
class LearningMode:
    def __init__(self):
        self.improvements = []
    
    def record_improvement(self, original, modified, reason, result):
        self.improvements.append({
            "timestamp": datetime.now(),
            "original_prompt": original,
            "modified_prompt": modified,
            "change_reason": reason,
            "result_quality": result  # 1-5 scale
        })
    
    def get_recommendations(self, scene_type):
        """éå»ã®æ”¹å–„ã‹ã‚‰å­¦ç¿’ã—ãŸæ¨å¥¨äº‹é …ã‚’è¿”ã™"""
        relevant = [i for i in self.improvements 
                   if scene_type in i["original_prompt"]]
        
        if relevant:
            best_practices = analyze_improvements(relevant)
            return best_practices
        return None

# ä½¿ç”¨ä¾‹
learning = LearningMode()

# æ”¹å–„ã‚’è¨˜éŒ²
learning.record_improvement(
    original="classroom scene",
    modified="bright classroom, 20 students, dynamic composition",
    reason="Too dark and empty",
    result=4
)

# æ¬¡å›ã®æ¨å¥¨ã‚’å–å¾—
recommendations = learning.get_recommendations("classroom")
print(f"æ•™å®¤ã‚·ãƒ¼ãƒ³ã®æ¨å¥¨: {recommendations}")
```

### 6.6 ãƒ—ãƒªã‚»ãƒƒãƒˆãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆä½¿ç”¨

```python
# ã‚ˆãã‚ã‚‹ç”¨é€”ã®ãƒ—ãƒªã‚»ãƒƒãƒˆ
PRESETS = {
    "educational": {
        "style": "clear and informative",
        "pacing": "steady",
        "camera_work": "mostly static with slow movements",
        "composition": "rule of thirds for clarity"
    },
    "marketing": {
        "style": "dynamic and engaging", 
        "pacing": "fast",
        "camera_work": "energetic movements",
        "composition": "varied for visual interest"
    },
    "narrative": {
        "style": "cinematic",
        "pacing": "varies with story",
        "camera_work": "motivated by emotion",
        "composition": "supports storytelling"
    }
}

# ãƒ—ãƒªã‚»ãƒƒãƒˆã‚’ä½¿ç”¨
storyboard = generator.generate_complete_storyboard(
    "æ–°è£½å“ã‚¹ãƒãƒ¼ãƒˆãƒ•ã‚©ãƒ³ã®ç´¹ä»‹",
    config=PRESETS["marketing"]
)
```

### 6.7 å‡ºåŠ›ä¾‹ï¼ˆã‚¤ãƒ†ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³å±¥æ­´ä»˜ãï¼‰

```markdown
# é’æ˜¥ã®æ–‡åŒ–ç¥­

## Cut 1 (10ç§’) - ãƒãƒ¼ã‚¸ãƒ§ãƒ³å±¥æ­´ã‚ã‚Š

### æœ€çµ‚ç‰ˆ
![Cut 1 Final](output/frames/cut_01_v3.jpg)

**ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆå¤‰æ›´å±¥æ­´**:
- v1: "classroom scene" â†’ æš—ã™ãã‚‹
- v2: + "bright lighting" â†’ äººãŒå°‘ãªã„  
- v3: + "20 students, busy atmosphere" â†’ âœ… æ¡ç”¨

**æœ€çµ‚ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ**:
```
extreme wide shot, bright morning classroom,
20 students preparing for festival,
colorful decorations, busy atmosphere,
rule of thirds, warm lighting, anime style, 16:9
```

**ItoVãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ**:
```
slow zoom in revealing more details,
students moving naturally, papers rustling,
10 seconds, building excitement,
maintain composition balance
```
```

### 6.8 ãƒ“ãƒ‡ã‚ªãƒ¢ãƒ‡ãƒ«åˆ¥ç”Ÿæˆï¼ˆVeo3.1/Sora2å¯¾å¿œï¼‰

#### è‡ªå‹•ãƒ¢ãƒ‡ãƒ«é¸æŠã§ã®ç”Ÿæˆ

```python
from ai_video_storyboard import StoryboardGenerator, VideoModelOptimizer

# ãƒ¢ãƒ‡ãƒ«æœ€é©åŒ–æ©Ÿèƒ½ã‚’æœ‰åŠ¹åŒ–
generator = StoryboardGenerator()
optimizer = VideoModelOptimizer(target_model="auto")

# ã‚¹ãƒˆãƒ¼ãƒªãƒ¼ãƒœãƒ¼ãƒ‰ç”Ÿæˆ
storyboard = generator.generate_complete_storyboard(
    "ã‚¹ãƒãƒ¼ãƒ„å¤§ä¼šã§ã®ãƒ‰ãƒ©ãƒãƒãƒƒã‚¯ãªé€†è»¢å‹åˆ©ã®ç¬é–“"
)

# å„ã‚«ãƒƒãƒˆã«æœ€é©ãªãƒ¢ãƒ‡ãƒ«ã‚’è‡ªå‹•é¸æŠ
for cut in storyboard.cuts:
    # ã‚·ãƒ¼ãƒ³ã‚¿ã‚¤ãƒ—ã‚’åˆ†æ
    scene_type = analyzer.detect_scene_type(cut)
    
    # ä¸¡ãƒ¢ãƒ‡ãƒ«ç”¨ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆç”Ÿæˆ
    prompts = optimizer.generate_optimized_prompt(cut)
    
    # æ¨å¥¨ãƒ¢ãƒ‡ãƒ«ã‚’æç¤º
    recommendation = optimizer.recommend_model(scene_type)
    
    print(f"\nCut {cut.cut_number}: {scene_type}")
    print(f"æ¨å¥¨ãƒ¢ãƒ‡ãƒ«: {recommendation['model']}")
    print(f"ç†ç”±: {recommendation['reason']}")
    
    # ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆè¡¨ç¤º
    print("\nã€Veo3.1ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã€‘")
    print(prompts['veo3'])
    print("\nã€Sora2ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã€‘")
    print(prompts['sora2'])
```

### 6.9 ã‚­ãƒ¼ãƒ“ã‚¸ãƒ¥ã‚¢ãƒ«ç”»åƒå…¥åŠ›ã§ã®ç”Ÿæˆ

#### ç”»åƒã‚’ä½¿ã£ãŸä¸–ç•Œè¦³çµ±ä¸€

```python
from ai_video_storyboard import StoryboardGenerator, ImageAnalyzer

# ç”»åƒè§£æå™¨ã‚’åˆæœŸåŒ–
analyzer = ImageAnalyzer()
generator = StoryboardGenerator()

# ã‚­ãƒ¼ãƒ“ã‚¸ãƒ¥ã‚¢ãƒ«ç”»åƒã‚’è§£æ
key_visual = "path/to/concept_art.jpg"
visual_analysis = analyzer.analyze_key_visual(key_visual)

print("=== ã‚­ãƒ¼ãƒ“ã‚¸ãƒ¥ã‚¢ãƒ«è§£æçµæœ ===")
print(f"ã‚¢ãƒ¼ãƒˆã‚¹ã‚¿ã‚¤ãƒ«: {visual_analysis['style']}")
print(f"ä¸»è¦è‰²å½©: {visual_analysis['colors']}")
print(f"é›°å›²æ°—: {visual_analysis['mood']}")
print(f"æ¤œå‡ºã•ã‚ŒãŸè¦ç´ : {visual_analysis['elements']}")

# ã‚¹ã‚¿ã‚¤ãƒ«ã‚¬ã‚¤ãƒ‰ã‚’ç”Ÿæˆ
style_guide = analyzer.generate_style_guide(visual_analysis)

# ã‚¹ã‚¿ã‚¤ãƒ«ã‚¬ã‚¤ãƒ‰ã‚’é©ç”¨ã—ã¦çµµã‚³ãƒ³ãƒ†ç”Ÿæˆ
storyboard = generator.generate_complete_storyboard(
    story="é­”æ³•å­¦æ ¡ã§ã®ä¸€æ—¥ã‚’æã60ç§’ã®ãƒ•ã‚¡ãƒ³ã‚¿ã‚¸ãƒ¼",
    key_visual_style=style_guide,  # ã‚­ãƒ¼ãƒ“ã‚¸ãƒ¥ã‚¢ãƒ«ã®ã‚¹ã‚¿ã‚¤ãƒ«ã‚’ç¶™æ‰¿
    config={
        "enforce_visual_consistency": True,
        "style_strength": 0.8  # 0.0-1.0ã§ã‚¹ã‚¿ã‚¤ãƒ«å½±éŸ¿åº¦ã‚’èª¿æ•´
    }
)

# å„ã‚«ãƒƒãƒˆã«ã‚¹ã‚¿ã‚¤ãƒ«ãŒåæ˜ ã•ã‚Œã¦ã„ã‚‹ã‹ç¢ºèª
for cut in storyboard.cuts:
    print(f"\nCut {cut.cut_number}:")
    print(f"ã‚¹ã‚¿ã‚¤ãƒ«è¦ç´ : {cut.style_modifiers}")
    print(f"è‰²å½©æŒ‡å®š: {cut.color_palette}")
```

#### å®Ÿä¾‹ï¼šã‚¢ãƒ‹ãƒ¡ã‚¹ã‚¿ã‚¤ãƒ«ã®ã‚­ãƒ¼ãƒ“ã‚¸ãƒ¥ã‚¢ãƒ«é©ç”¨

```python
# ã‚­ãƒ¼ãƒ“ã‚¸ãƒ¥ã‚¢ãƒ«è§£æçµæœ
visual_analysis = {
    "style": "anime_2d_cel_shaded",
    "colors": {
        "primary": ["#FF6B6B", "#4ECDC4"],  # èµ¤ã¨ã‚¿ãƒ¼ã‚³ã‚¤ã‚º
        "secondary": ["#FFE66D", "#A8E6CF"],
        "temperature": "warm_with_cool_accents"
    },
    "mood": "vibrant_energetic",
    "elements": ["school_uniform", "cherry_blossoms", "modern_architecture"],
    "composition": "dynamic_diagonal"
}

# è‡ªå‹•ç”Ÿæˆã•ã‚Œã‚‹ã‚¹ã‚¿ã‚¤ãƒ«ã‚¬ã‚¤ãƒ‰
style_guide = {
    "prompt_modifiers": [
        "anime style",
        "cel-shaded",
        "vibrant colors",
        "warm lighting with cool shadows",
        "cherry blossom petals in background"
    ],
    "technical_specs": {
        "line_art": "clean black outlines",
        "shading": "cel-shading with 3-4 levels",
        "highlights": "bright specular highlights",
        "background": "detailed but slightly softer than foreground"
    },
    "consistency_rules": [
        "maintain color palette: #FF6B6B, #4ECDC4 as main",
        "keep diagonal composition tendency",
        "include cherry blossom motif in each scene"
    ]
}

# å„ã‚«ãƒƒãƒˆã¸ã®é©ç”¨çµæœ
cut_1_prompt_before = "classroom scene, students studying"

cut_1_prompt_after = """
anime style, cel-shaded, classroom scene, students studying,
vibrant colors with #FF6B6B and #4ECDC4 accents,
warm lighting with cool shadows,
cherry blossom petals visible through window,
clean black outlines, cel-shading with 3-4 levels,
diagonal composition, detailed background,
16:9 aspect ratio
"""
```

#### è¤‡æ•°ã®å‚è€ƒç”»åƒã‚’ä½¿ç”¨

```python
# è¤‡æ•°ã®å‚è€ƒç”»åƒã‹ã‚‰ä¸–ç•Œè¦³ã‚’æ§‹ç¯‰
reference_images = [
    "path/to/character_design.jpg",  # ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼ãƒ‡ã‚¶ã‚¤ãƒ³
    "path/to/background_art.jpg",     # èƒŒæ™¯ç¾è¡“
    "path/to/color_reference.jpg"     # è‰²å½©è¨­è¨ˆ
]

# å„ç”»åƒã‚’è§£æã—ã¦çµ±åˆ
combined_analysis = analyzer.analyze_multiple_references(reference_images)

# å½¹å‰²åˆ¥ã«é‡ã¿ä»˜ã‘
weighted_style = analyzer.create_weighted_style_guide(
    combined_analysis,
    weights={
        "character": 0.4,
        "background": 0.3,
        "color": 0.3
    }
)
```

### 6.10 BGMç”Ÿæˆãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã®ä½œæˆ

#### åŸºæœ¬çš„ãªBGMç”Ÿæˆ

```python
from ai_video_storyboard import MusicPromptGenerator

# éŸ³æ¥½ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆç”Ÿæˆå™¨ã‚’åˆæœŸåŒ–
music_gen = MusicPromptGenerator()

# å®Œæˆã—ãŸçµµã‚³ãƒ³ãƒ†ã‹ã‚‰BGMãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ç”Ÿæˆ
storyboard = load_completed_storyboard("storyboard.json")

# æ„Ÿæƒ…æ›²ç·šã‚’åˆ†æ
emotional_arc = music_gen.analyze_emotional_arc(storyboard)

print("=== æ„Ÿæƒ…æ›²ç·šåˆ†æ ===")
for point in emotional_arc:
    print(f"Cut {point['cut']}: {point['emotion']} (å¼·åº¦: {point['intensity']}/10)")

# éŸ³æ¥½ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã‚’è‡ªå‹•åˆ†å‰²
music_sections = music_gen.create_music_sections(storyboard)

print(f"\n=== éŸ³æ¥½ã‚»ã‚¯ã‚·ãƒ§ãƒ³ï¼ˆ{len(music_sections)}åˆ†å‰²ï¼‰===")
for i, section in enumerate(music_sections, 1):
    cuts = [c.cut_number for c in section]
    duration = sum(c.duration for c in section)
    print(f"Section {i}: ã‚«ãƒƒãƒˆ{cuts} ({duration}ç§’)")

# Sunoç”¨ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ç”Ÿæˆ
suno_prompts = music_gen.generate_suno_prompts(music_sections, storyboard)
```

#### ç”Ÿæˆã•ã‚Œã‚‹Sunoãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã®ä¾‹

```python
# é’æ˜¥å­¦åœ’ã‚¹ãƒˆãƒ¼ãƒªãƒ¼ã®BGMãƒ—ãƒ­ãƒ³ãƒ—ãƒˆä¾‹
suno_output = {
    "project": "é’æ˜¥ã®æ–‡åŒ–ç¥­",
    "total_duration": 60,
    "sections": [
        {
            "id": 1,
            "name": "Morning Preparation",
            "cuts": [1, 2, 3],
            "duration": 25,
            "suno_prompt": """
                [Hopeful intro]
                Genre: Cinematic J-Pop
                Mood: Anticipation, morning freshness
                Instruments: Acoustic piano, light strings, soft percussion
                Tempo: 80 BPM, 4/4 time
                Energy: Starting at 3/10, building to 5/10
                Key: C Major
                Style: Ghibli-inspired, warm and nostalgic
            """,
            "lyrics_suggestion": "Instrumental recommended"
        },
        {
            "id": 2,
            "name": "Festival Energy",
            "cuts": [4, 5, 6],
            "duration": 20,
            "suno_prompt": """
                [Energetic main theme]
                Genre: Upbeat J-Rock/Pop fusion
                Mood: Excitement, teamwork, youth
                Instruments: Electric guitar, bass, drums, synth pad, bells
                Tempo: 128 BPM, 4/4 time
                Energy: Steady 7/10
                Key: G Major
                Style: Modern anime opening feel
                Features: Catchy melody hook, rhythmic guitar riffs
            """,
            "lyrics_suggestion": "Optional: 'ã¿ã‚“ãªã§ä½œã‚‹æ€ã„å‡º' theme"
        },
        {
            "id": 3,
            "name": "Triumphant Finale",
            "cuts": [7, 8],
            "duration": 15,
            "suno_prompt": """
                [Epic finale]
                Genre: Orchestral Pop
                Mood: Triumph, joy, emotional peak
                Instruments: Full orchestra, choir, electric guitar solo
                Tempo: 140 BPM, building to finale
                Energy: 8/10 to 10/10
                Key: D Major
                Style: Cinematic crescendo
                Features: Soaring strings, triumphant brass, emotional climax
            """,
            "lyrics_suggestion": "Wordless vocals/choir"
        }
    ],
    "transitions": [
        {
            "from_section": 1,
            "to_section": 2,
            "cut": 4,
            "type": "drum_fill_energy_boost"
        },
        {
            "from_section": 2,
            "to_section": 3,
            "cut": 7,
            "type": "dramatic_pause_then_explosion"
        }
    ],
    "sync_points": [
        {"time": "0:00", "event": "Fade in with first image"},
        {"time": "0:25", "event": "Energy boost at Cut 4"},
        {"time": "0:45", "event": "Climax build at Cut 7"},
        {"time": "0:55", "event": "Final crescendo"},
        {"time": "0:58", "event": "Ending chord with final frame"}
    ]
}
```

#### é«˜åº¦ãªBGMè¨­å®š

```python
# ã‚¸ãƒ£ãƒ³ãƒ«åˆ¥ãƒ—ãƒªã‚»ãƒƒãƒˆä½¿ç”¨
music_gen.use_preset("anime_opening")
music_gen.use_preset("documentary")
music_gen.use_preset("horror_suspense")

# ã‚«ã‚¹ã‚¿ãƒ ãƒ ãƒ¼ãƒ‰æ›²ç·šã‚’å®šç¾©
custom_mood_curve = [
    {"time": 0, "mood": "mysterious", "energy": 3},
    {"time": 15, "mood": "building_tension", "energy": 5},
    {"time": 30, "mood": "action_peak", "energy": 9},
    {"time": 45, "mood": "emotional_resolution", "energy": 6},
    {"time": 55, "mood": "peaceful_ending", "energy": 2}
]

# æ¥½å™¨ç·¨æˆã‚’æŒ‡å®š
instrument_preference = {
    "primary": ["piano", "violin", "cello"],
    "secondary": ["flute", "harp"],
    "avoid": ["electric_guitar", "synthesizer"]
}

# è©³ç´°è¨­å®šã§BGMç”Ÿæˆ
suno_prompts = music_gen.generate_suno_prompts(
    music_sections,
    storyboard,
    config={
        "mood_curve": custom_mood_curve,
        "instruments": instrument_preference,
        "genre": "classical_crossover",
        "reference_tracks": ["ä¹…çŸ³è­²", "John Williams"],
        "avoid_sudden_changes": True,
        "seamless_loops": False
    }
)
```

#### BGMã¨ãƒ“ãƒ‡ã‚ªã®åŒæœŸè¡¨

```python
# ã‚¿ã‚¤ãƒŸãƒ³ã‚°ã‚·ãƒ¼ãƒˆç”Ÿæˆ
timing_sheet = music_gen.generate_timing_sheet(suno_prompts, storyboard)

# ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆå½¢å¼
timing_export = {
    "format": "video_editor_markers",
    "markers": [
        {"time": "00:00:00.00", "label": "Music Start", "color": "green"},
        {"time": "00:00:25.00", "label": "Section 2 - Energy Up", "color": "yellow"},
        {"time": "00:00:45.00", "label": "Climax Start", "color": "red"},
        {"time": "00:00:55.00", "label": "Final Crescendo", "color": "purple"}
    ],
    "automation": {
        "volume": [
            {"time": 0, "value": 0.7},
            {"time": 25, "value": 0.9},
            {"time": 45, "value": 1.0},
            {"time": 58, "value": 0.8},
            {"time": 60, "value": 0.0}
        ]
    }
}

# DaVinci Resolveã‚„Premiere Proç”¨ã«XMLå‡ºåŠ›
export_for_video_editor(timing_export, format="fcpxml")
```

#### å‡ºåŠ›ä¾‹ï¼šã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã‚·ãƒ¼ãƒ³

```python
# Cut 5: ã‚¯ãƒ©ã‚¤ãƒãƒƒã‚¯ã‚¹ã®ã‚´ãƒ¼ãƒ«ã‚·ãƒ¼ãƒ³
scene_data = {
    "cut_number": 5,
    "scene_type": "action",
    "duration": 8,
    "description": "æ±ºå‹ã‚´ãƒ¼ãƒ«ã‚’æ±ºã‚ã‚‹ç¬é–“"
}

# Veo3.1ç”¨ï¼ˆæŠ€è¡“çš„ç²¾åº¦é‡è¦–ï¼‰
veo3_prompt = """
[Camera Settings]
Shot: Wide to Close-up transition
Duration: 8 seconds
FPS: 60 (slow-motion capability)
Resolution: 4K

[Camera Movement]
0-2s: Wide shot, static
2-4s: Fast dolly in at 3m/s
4-6s: Arc around subject, 45 degrees
6-8s: Slow zoom to face, decelerate

[Action Timeline]
0.0-1.5s: Player runs with ball, full speed
1.5-2.0s: Wind up for kick
2.0-2.2s: Ball contact (slow motion trigger)
2.2-4.0s: Ball trajectory tracking
4.0-6.0s: Player celebration begins
6.0-8.0s: Emotional close-up reaction

[Physics]
Ball speed: 25m/s
Rotation: 600rpm
Trajectory: Parabolic arc, 15-degree angle
Wind: 2m/s from left

[Rendering]
Motion blur: Enabled for ball
DOF: f/2.8, focus tracking on player
Particles: Grass and dust on impact
"""

# Sora2ç”¨ï¼ˆãƒ‰ãƒ©ãƒãƒãƒƒã‚¯ãªè¡¨ç¾é‡è¦–ï¼‰
sora2_prompt = """
The decisive moment unfolds in breathtaking detail as 
the striker breaks free from defenders, the ball at 
their feet like an extension of their soul. Time seems 
to slow as they approach the goal, every muscle tensed 
with determination. 

The kick is poetry in motion - foot meets ball in a 
perfect symphony of power and precision. The camera 
swoops dramatically around the action, capturing the 
ball's majestic arc through the air, spinning with 
dream-like clarity against the sky.

As the net ripples with impact, we push in close to 
catch the raw emotion exploding across the player's face - 
pure joy, relief, and triumph all at once. The crowd's 
roar seems distant as we focus on this singular moment 
of glory, rendered in cinematic slow motion that makes 
every detail eternal.

Style: Epic sports cinematography with dramatic lighting 
and selective slow motion for maximum emotional impact.
"""

# æ¨å¥¨çµæœ
recommendation = {
    "model": "veo3",
    "reason": "é«˜é€Ÿã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã€ç‰©ç†æ¼”ç®—ãŒé‡è¦ã€æ™‚é–“åˆ¶å¾¡ãŒå¿…è¦",
    "confidence": 0.85,
    "alternative_note": "Sora2ã‚‚æ„Ÿæƒ…è¡¨ç¾éƒ¨åˆ†ã§ã¯åŠ¹æœçš„"
}
```

#### ãƒ¢ãƒ‡ãƒ«åˆ¥ã®å¼·ã¿ã‚’æ´»ã‹ã—ãŸä½¿ã„åˆ†ã‘

```python
# ã‚«ãƒƒãƒˆåˆ¥ãƒ¢ãƒ‡ãƒ«é¸æŠæˆ¦ç•¥
storyboard_with_models = optimize_for_models(storyboard)

print("ã€æœ€é©åŒ–ã•ã‚ŒãŸãƒ¢ãƒ‡ãƒ«å‰²ã‚Šå½“ã¦ã€‘")
for cut in storyboard_with_models.cuts:
    print(f"Cut {cut.cut_number}: {cut.scene_description[:30]}...")
    print(f"  â†’ {cut.recommended_model}")
    print(f"  ç†ç”±: {cut.model_reason}")

# å‡ºåŠ›ä¾‹ï¼š
"""
ã€æœ€é©åŒ–ã•ã‚ŒãŸãƒ¢ãƒ‡ãƒ«å‰²ã‚Šå½“ã¦ã€‘
Cut 1: æœã®ç«¶æŠ€å ´å…¨æ™¯...
  â†’ Veo3.1
  ç†ç”±: åºƒç¯„å›²ã®ç²¾å¯†ãªæå†™ã€å»ºç¯‰ç‰©ã®æ­£ç¢ºæ€§
  
Cut 2: é¸æ‰‹ã®è¡¨æƒ…ã‚¢ãƒƒãƒ—...
  â†’ Sora2
  ç†ç”±: ç·Šå¼µæ„Ÿã®ç¹Šç´°ãªè¡¨ç¾ã€å†…é¢ã®æå†™

Cut 3: ã‚¹ã‚¿ãƒ¼ãƒˆãƒ€ãƒƒã‚·ãƒ¥...
  â†’ Veo3.1
  ç†ç”±: é«˜é€Ÿå‹•ä½œã€æ­£ç¢ºãªã‚¿ã‚¤ãƒŸãƒ³ã‚°åˆ¶å¾¡

Cut 4: è¦³å®¢ã®åå¿œ...
  â†’ Sora2
  ç†ç”±: ç¾¤é›†ã®è‡ªç„¶ãªæ„Ÿæƒ…è¡¨ç¾ã€é›°å›²æ°—é‡è¦–

Cut 5: ã‚´ãƒ¼ãƒ«ã‚·ãƒ¼ãƒ³...
  â†’ Veo3.1
  ç†ç”±: è¤‡é›‘ãªç‰©ç†æ¼”ç®—ã€ã‚¹ãƒ­ãƒ¼ãƒ¢ãƒ¼ã‚·ãƒ§ãƒ³
"""
```

#### ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆå¤‰æ›æ©Ÿèƒ½ã®ä½¿ç”¨

```python
# æ—¢å­˜ã®Veo3ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’Sora2ç”¨ã«å¤‰æ›
original_veo3 = load_existing_prompt("veo3_format.txt")

# è‡ªå‹•å¤‰æ›
converted = optimizer.convert_between_models(
    prompt=original_veo3,
    from_model="veo3",
    to_model="sora2"
)

print("ã€å¤‰æ›å‰ - Veo3ã€‘")
print(original_veo3[:200] + "...")

print("\nã€å¤‰æ›å¾Œ - Sora2ã€‘")
print(converted[:200] + "...")

# å¤‰æ›å“è³ªã®ç¢ºèª
quality_check = optimizer.verify_conversion(original_veo3, converted)
print(f"\nå¤‰æ›å“è³ªã‚¹ã‚³ã‚¢: {quality_check['score']}/100")
print(f"ä¿æŒã•ã‚ŒãŸè¦ç´ : {quality_check['preserved_elements']}")
print(f"è¿½åŠ ã•ã‚ŒãŸè¦ç´ : {quality_check['added_elements']}")
print(f"å¤±ã‚ã‚ŒãŸè¦ç´ : {quality_check['lost_elements']}")
```

#### A/Bãƒ†ã‚¹ãƒˆãƒ¢ãƒ¼ãƒ‰

```python
# ä¸¡ãƒ¢ãƒ‡ãƒ«ã§ç”Ÿæˆã—ã¦æ¯”è¼ƒ
def run_ab_test(scene_description):
    # ä¸¡ãƒ¢ãƒ‡ãƒ«ç”¨ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆç”Ÿæˆ
    results = generator.generate_ab_test(scene_description)
    
    # ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ä»˜ãã§ä¿å­˜
    save_ab_test_results({
        "timestamp": datetime.now(),
        "scene": scene_description,
        "veo3": {
            "prompt": results["veo3_prompt"],
            "generation_time": results["veo3_time"],
            "estimated_cost": "$0.10"
        },
        "sora2": {
            "prompt": results["sora2_prompt"],
            "generation_time": results["sora2_time"],
            "estimated_cost": "$0.08"
        },
        "comparison": {
            "technical_accuracy": "Veo3 > Sora2",
            "artistic_quality": "Sora2 > Veo3",
            "generation_speed": "Sora2 > Veo3",
            "cost_efficiency": "Sora2 > Veo3"
        }
    })

# ä½¿ç”¨ä¾‹
ab_test_results = run_ab_test(
    "å¤•æš®ã‚Œã®å±‹ä¸Šã§ä¸€äººä½‡ã‚€ä¸»äººå…¬ã®æ„Ÿå‚·çš„ãªã‚·ãƒ¼ãƒ³"
)
```

## 7. å®Ÿè£…ä¸Šã®èª²é¡Œã¨è§£æ±ºç­–

### 7.1 ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼ä¸€è²«æ€§ã®èª²é¡Œ

**èª²é¡Œ**: 
- ç•°ãªã‚‹ã‚«ãƒƒãƒˆã§åŒã˜ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼ã‚’å®Œå…¨ã«ä¸€è²«ã—ã¦ç”Ÿæˆã™ã‚‹ã“ã¨ã¯å›°é›£
- ä¸‰é¢å›³ã®è‡ªå‹•ç”Ÿæˆã¯ç¾åœ¨ã®æŠ€è¡“ã§ã¯é™ç•ŒãŒã‚ã‚‹

**è§£æ±ºç­–ï¼ˆã‚¤ãƒ†ãƒ¬ãƒ¼ãƒ†ã‚£ãƒ–ã‚¢ãƒ—ãƒ­ãƒ¼ãƒï¼‰**:

1. **åˆå›ç”Ÿæˆã§åŸºæº–ã‚’ç¢ºç«‹**:
```python
# Cut 1ã§ä¸»äººå…¬ã‚’ç”Ÿæˆ
character_base = "teenage student, short black hair, blue school uniform, cheerful expression"

# æˆåŠŸã—ãŸãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’è¨˜éŒ²
successful_character_prompt = """
medium shot, teenage student with short black hair,
neat blue school uniform with white collar,
bright brown eyes, cheerful smile,
standing in classroom, morning light
"""
```

2. **å¾Œç¶šã‚«ãƒƒãƒˆã§ä¸€è²«æ€§ã‚’ç¶­æŒ**:
```python
# æˆåŠŸã—ãŸç‰¹å¾´ã‚’å…¨ã‚«ãƒƒãƒˆã«ç¶™æ‰¿
for cut in storyboard.cuts[1:]:
    if "ä¸»äººå…¬" in cut.scene_description:
        cut.image_prompt = apply_character_consistency(
            base_prompt=cut.image_prompt,
            character_features=successful_character_prompt
        )
```

3. **ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆä¿®æ­£ã§èª¿æ•´**:
```python
# ä¸€è²«æ€§ãŒå´©ã‚ŒãŸå ´åˆã®ä¿®æ­£ãƒ‘ã‚¿ãƒ¼ãƒ³
consistency_fixes = {
    "hair_color": "explicitly state: short BLACK hair, not brown",
    "uniform": "blue school uniform with WHITE collar, navy blue blazer",
    "face": "maintain youthful appearance, round face, large eyes"
}
```

4. **ãƒ™ã‚¹ãƒˆãƒ—ãƒ©ã‚¯ãƒ†ã‚£ã‚¹**:
- æœ€åˆã®ã‚«ãƒƒãƒˆã§è©³ç´°ã«å®šç¾©
- ç‰¹å¾´çš„ãªè¦ç´ ã‚’3-4å€‹ã«çµã‚‹
- å„ã‚«ãƒƒãƒˆã§å¿…ãšåŒã˜ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’ä½¿ç”¨
- ç”Ÿæˆå¾Œã™ãã«ä¸€è²«æ€§ã‚’ãƒã‚§ãƒƒã‚¯

### 7.2 APIåˆ¶é™ã¸ã®å¯¾å¿œ

**èª²é¡Œ**:
- ãƒ¬ãƒ¼ãƒˆåˆ¶é™ï¼ˆ60ãƒªã‚¯ã‚¨ã‚¹ãƒˆ/åˆ†ï¼‰
- ã‚³ã‚¹ãƒˆï¼ˆ$0.03/ç”»åƒï¼‰
- ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆã‚¨ãƒ©ãƒ¼

**è§£æ±ºç­–ï¼ˆåŠ¹ç‡çš„ãªç”Ÿæˆæˆ¦ç•¥ï¼‰**:

1. **ãƒ—ãƒ­ã‚°ãƒ¬ãƒƒã‚·ãƒ–ç”Ÿæˆ**:
```python
class ProgressiveGenerator:
    def __init__(self):
        self.rate_limiter = RateLimiter(max_per_minute=60)
        self.cost_tracker = CostTracker(price_per_image=0.03)
    
    def generate_storyboard(self, story, mode="draft"):
        if mode == "draft":
            # ã¾ãšä½è§£åƒåº¦oré‡è¦ã‚«ãƒƒãƒˆã®ã¿ç”Ÿæˆ
            return self.generate_key_frames_only(story)
        elif mode == "iterative":
            # 1ã‚«ãƒƒãƒˆãšã¤ç¢ºèªã—ãªãŒã‚‰ç”Ÿæˆ
            return self.generate_with_confirmation(story)
        elif mode == "final":
            # ç¢ºå®šã—ãŸãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã§å…¨ã‚«ãƒƒãƒˆç”Ÿæˆ
            return self.generate_all_frames(story)
```

2. **ã‚³ã‚¹ãƒˆæœ€é©åŒ–**:
```python
# ãƒ‰ãƒ©ã‚¤ãƒ©ãƒ³ãƒ¢ãƒ¼ãƒ‰ï¼ˆç”»åƒç”Ÿæˆãªã—ï¼‰
def dry_run(story):
    """ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã®ã¿ç”Ÿæˆã—ã¦ã‚³ã‚¹ãƒˆã‚’ç¢ºèª"""
    storyboard = create_storyboard_structure(story)
    prompts = generate_prompts(storyboard)
    
    estimated_cost = len(prompts) * 0.03
    print(f"äºˆæƒ³ã‚³ã‚¹ãƒˆ: ${estimated_cost:.2f}")
    print(f"ç”Ÿæˆã•ã‚Œã‚‹ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ:")
    for p in prompts:
        print(f"  - {p[:50]}...")
    
    return storyboard, prompts

# é¸æŠçš„ç”Ÿæˆ
def selective_generation(storyboard, important_cuts_only=True):
    """é‡è¦ãªã‚«ãƒƒãƒˆã®ã¿ç”»åƒç”Ÿæˆ"""
    if important_cuts_only:
        # ã‚ªãƒ¼ãƒ—ãƒ‹ãƒ³ã‚°ã€ã‚¯ãƒ©ã‚¤ãƒãƒƒã‚¯ã‚¹ã€ã‚¨ãƒ³ãƒ‡ã‚£ãƒ³ã‚°ã®ã¿
        key_cuts = [1, len(storyboard.cuts)//2, len(storyboard.cuts)]
        for cut_num in key_cuts:
            generate_image(storyboard.cuts[cut_num-1])
```

3. **ã‚¨ãƒ©ãƒ¼å‡¦ç†ã¨ãƒªãƒˆãƒ©ã‚¤**:
```python
def robust_image_generation(prompt, max_retries=3):
    """ã‚¨ãƒ©ãƒ¼æ™‚ã®è‡ªå‹•ãƒªãƒˆãƒ©ã‚¤ã¨ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯"""
    for attempt in range(max_retries):
        try:
            if attempt > 0:
                # ãƒªãƒˆãƒ©ã‚¤æ™‚ã¯ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’å°‘ã—ç°¡ç•¥åŒ–
                prompt = simplify_prompt(prompt, level=attempt)
            
            result = generate_image(prompt)
            return result
            
        except RateLimitError:
            wait_time = calculate_backoff(attempt)
            print(f"ãƒ¬ãƒ¼ãƒˆåˆ¶é™ã€‚{wait_time}ç§’å¾…æ©Ÿ...")
            time.sleep(wait_time)
            
        except SafetyFilterError:
            # ã‚»ãƒ¼ãƒ•ãƒ†ã‚£ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ã«å¼•ã£ã‹ã‹ã£ãŸå ´åˆ
            prompt = make_prompt_safer(prompt)
            print("ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’èª¿æ•´ã—ã¦å†è©¦è¡Œ...")
            
    return None  # å¤±æ•—æ™‚ã¯Noneã‚’è¿”ã™
```

### 7.3 å“è³ªç®¡ç†

**å®Ÿè£…ã™ã‚‹å“è³ªãƒã‚§ãƒƒã‚¯**:

1. **ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆå“è³ªã®è‡ªå‹•ãƒã‚§ãƒƒã‚¯**:
```python
class PromptQualityChecker:
    def validate_prompt(self, prompt):
        issues = []
        
        # é•·ã•ãƒã‚§ãƒƒã‚¯
        if len(prompt) > 500:
            issues.append("ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãŒé•·ã™ãã¾ã™ï¼ˆ500æ–‡å­—ä»¥å†…æ¨å¥¨ï¼‰")
        
        # å¿…é ˆè¦ç´ ãƒã‚§ãƒƒã‚¯
        required = ["shot size", "composition", "aspect ratio"]
        for req in required:
            if req not in prompt.lower():
                issues.append(f"'{req}'ãŒå«ã¾ã‚Œã¦ã„ã¾ã›ã‚“")
        
        # çŸ›ç›¾ãƒã‚§ãƒƒã‚¯
        if "close-up" in prompt and "full body" in prompt:
            issues.append("ã‚·ãƒ§ãƒƒãƒˆã‚µã‚¤ã‚ºã«çŸ›ç›¾ãŒã‚ã‚Šã¾ã™")
        
        return issues
```

2. **ã‚¹ã‚¿ã‚¤ãƒ«ä¸€è²«æ€§ã®æ¤œè¨¼**:
```python
def check_style_consistency(storyboard):
    """å…¨ã‚«ãƒƒãƒˆã§ã‚¹ã‚¿ã‚¤ãƒ«ãŒçµ±ä¸€ã•ã‚Œã¦ã„ã‚‹ã‹ç¢ºèª"""
    
    base_style = extract_style(storyboard.cuts[0].image_prompt)
    inconsistencies = []
    
    for i, cut in enumerate(storyboard.cuts[1:], 2):
        current_style = extract_style(cut.image_prompt)
        if not styles_match(base_style, current_style):
            inconsistencies.append(f"Cut {i}: ã‚¹ã‚¿ã‚¤ãƒ«ã®ä¸ä¸€è‡´")
    
    if inconsistencies:
        print("âš ï¸ ã‚¹ã‚¿ã‚¤ãƒ«ã®ä¸€è²«æ€§ã«å•é¡ŒãŒã‚ã‚Šã¾ã™:")
        for issue in inconsistencies:
            print(f"  - {issue}")
        
        # è‡ªå‹•ä¿®æ­£ã®ææ¡ˆ
        suggest_style_fixes(storyboard)
```

3. **ã‚«ãƒƒãƒˆé–“ã®è«–ç†çš„æ•´åˆæ€§**:
```python
def verify_narrative_flow(storyboard):
    """ã‚¹ãƒˆãƒ¼ãƒªãƒ¼ã®æµã‚ŒãŒè«–ç†çš„ã‹ç¢ºèª"""
    
    for i in range(len(storyboard.cuts) - 1):
        current = storyboard.cuts[i]
        next_cut = storyboard.cuts[i + 1]
        
        # å ´æ‰€ã®æ€¥æ¿€ãªå¤‰åŒ–ã‚’ãƒã‚§ãƒƒã‚¯
        if "indoor" in current.scene_description and "outdoor" in next_cut.scene_description:
            if "transition" not in next_cut.scene_description:
                print(f"âš ï¸ Cut {i+1}â†’{i+2}: å ´é¢è»¢æ›ãŒæ€¥æ¿€ã§ã™")
        
        # æ™‚é–“ã®æµã‚Œã‚’ãƒã‚§ãƒƒã‚¯  
        if "night" in current.scene_description and "morning" in next_cut.scene_description:
            if i + 1 < len(storyboard.cuts) - 1:  # æœ€å¾Œä»¥å¤–
                print(f"âš ï¸ Cut {i+1}â†’{i+2}: æ™‚é–“ã®æµã‚ŒãŒä¸è‡ªç„¶ã‹ã‚‚ã—ã‚Œã¾ã›ã‚“")
```

### 7.4 ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æœ€é©åŒ–

**å®Ÿè£…ã™ã‚‹æœ€é©åŒ–**:

1. **ä¸¦åˆ—å‡¦ç†ï¼ˆæ³¨æ„æ·±ãä½¿ç”¨ï¼‰**:
```python
import asyncio
from concurrent.futures import ThreadPoolExecutor

async def generate_multiple_cuts(prompts, max_parallel=2):
    """è¤‡æ•°ã‚«ãƒƒãƒˆã‚’ä¸¦åˆ—ç”Ÿæˆï¼ˆãƒ¬ãƒ¼ãƒˆåˆ¶é™ã«æ³¨æ„ï¼‰"""
    
    with ThreadPoolExecutor(max_workers=max_parallel) as executor:
        tasks = []
        for i, prompt in enumerate(prompts):
            # ãƒ¬ãƒ¼ãƒˆåˆ¶é™ã‚’è€ƒæ…®ã—ã¦é…å»¶ã‚’å…¥ã‚Œã‚‹
            delay = i * 1.5  # 1.5ç§’é–“éš”
            task = asyncio.create_task(
                delayed_generation(prompt, delay)
            )
            tasks.append(task)
        
        results = await asyncio.gather(*tasks)
    return results
```

2. **ã‚­ãƒ£ãƒƒã‚·ãƒ³ã‚°æˆ¦ç•¥**:
```python
class PromptCache:
    def __init__(self):
        self.cache = {}
    
    def get_or_generate(self, scene_description, force_new=False):
        """é¡ä¼¼ã‚·ãƒ¼ãƒ³ã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’å†åˆ©ç”¨"""
        
        if not force_new:
            # é¡ä¼¼ã‚·ãƒ¼ãƒ³ã‚’æ¤œç´¢
            similar = self.find_similar(scene_description)
            if similar:
                print(f"â™»ï¸ é¡ä¼¼ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’å†åˆ©ç”¨: {similar['key'][:30]}...")
                return self.adapt_prompt(similar['prompt'], scene_description)
        
        # æ–°è¦ç”Ÿæˆ
        new_prompt = generate_new_prompt(scene_description)
        self.cache[hash(scene_description)] = {
            'key': scene_description,
            'prompt': new_prompt
        }
        return new_prompt
```

### 7.5 å®Ÿè£…å®Œäº†æ©Ÿèƒ½ï¼ˆ2025å¹´1æœˆå®Ÿè£…ï¼‰

#### 7.5.1 å‚ç…§ç”»åƒå¯¾å¿œï¼ˆImageGeneratorï¼‰

**å®Ÿè£…æ—¥**: 2025-01-11

**ç›®çš„**: Gemini 2.5 Flash Imageãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ç”¨ã—ãŸãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«ç”»åƒç”Ÿæˆã®å®Ÿç¾

**å®Ÿè£…å†…å®¹**:

1. **ãƒãƒ«ãƒç”»åƒå…¥åŠ›å¯¾å¿œ**:
   - æœ€å¤§3æšã®å‚ç…§ç”»åƒã‚’åŒæ™‚ã«ä½¿ç”¨å¯èƒ½ï¼ˆGemini 2.5 Flash Imageåˆ¶é™ï¼‰
   - PIL.Imageã‚’ä½¿ç”¨ã—ãŸç”»åƒèª­ã¿è¾¼ã¿
   - ç”»åƒã¨ãƒ†ã‚­ã‚¹ãƒˆãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã®çµ„ã¿åˆã‚ã›

2. **ã‚³ãƒ¼ãƒ‰å¤‰æ›´ç®‡æ‰€**: `core/video/image_generator.py`

```python
from PIL import Image

# å‚ç…§ç”»åƒãŒã‚ã‚‹å ´åˆã¯ç”»åƒã¨ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’çµ„ã¿åˆã‚ã›ã‚‹
content_parts = []
if hasattr(cut, 'reference_images') and cut.reference_images:
    # å‚ç…§ç”»åƒã‚’èª­ã¿è¾¼ã¿ï¼ˆæœ€å¤§3æšï¼‰
    reference_count = 0
    for ref_img_path in cut.reference_images[:3]:  # Gemini 2.5 Flash Image limit
        ref_path = Path(ref_img_path)
        if ref_path.exists():
            try:
                # PIL.Imageã§ç”»åƒã‚’èª­ã¿è¾¼ã¿
                img = Image.open(ref_path)
                content_parts.append(img)
                reference_count += 1
                print(f"    + Reference image {reference_count}: {ref_path.name}")
            except Exception as img_error:
                print(f"    âš ï¸  Failed to load reference image {ref_path.name}: {img_error}")
        else:
            print(f"    âš ï¸  Reference image not found: {ref_path}")

    if reference_count > 0:
        print(f"    â†’ Using {reference_count} reference image(s)")

# ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’è¿½åŠ 
content_parts.append(cut.image_prompt)

# ç”»åƒç”Ÿæˆãƒªã‚¯ã‚¨ã‚¹ãƒˆ
response = model.generate_content(content_parts)
```

3. **ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°**:
   - ç”»åƒãƒ•ã‚¡ã‚¤ãƒ«ãŒå­˜åœ¨ã—ãªã„å ´åˆã®è­¦å‘Š
   - ç”»åƒèª­ã¿è¾¼ã¿å¤±æ•—æ™‚ã®å€‹åˆ¥ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°
   - å‚ç…§ç”»åƒãªã—ã§ã®ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯å‹•ä½œ

4. **ä½¿ç”¨ä¾‹**ï¼ˆç™½æµœãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆï¼‰:
```python
# ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼å‚ç…§ï¼ˆ2æšï¼‰+ èƒŒæ™¯ç´ æï¼ˆ1æšï¼‰
cut.reference_images = [
    'materials/character_front.jpg',
    'materials/character_side.jpg',
    'materials/shirahama_beach.jpg'
]
```

**åŠ¹æœ**:
- ã‚¹ã‚¿ã‚¤ãƒ«ä¸€è²«æ€§ã®å¤§å¹…ãªå‘ä¸Š
- è¦³å…‰å†™çœŸã‚’èƒŒæ™¯ã¨ã—ã¦ä½¿ç”¨å¯èƒ½
- ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼å¤–è¦‹ã®ä¸€è²«æ€§ç¶­æŒ

---

#### 7.5.2 Veo 3 / Sora 2 å‹•ç”»ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆç”Ÿæˆ

**å®Ÿè£…æ—¥**: 2025-01-11

**ç›®çš„**: Runway Gen-3ã«ä»£ã‚ã‚‹æ¬¡ä¸–ä»£å‹•ç”»ç”Ÿæˆãƒ¢ãƒ‡ãƒ«ã¸ã®å¯¾å¿œ

**å®Ÿè£…å†…å®¹**:

1. **CutDataãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰æ‹¡å¼µ**: `core/video/storyboard_generator.py`

```python
@dataclass
class CutData:
    # ... existing fields ...
    video_prompt: str = ''  # Deprecated: å¾Œæ–¹äº’æ›æ€§ã®ãŸã‚æ®‹ã™
    generated_image_path: Optional[str] = None
    veo3_prompt: str = ''  # Veo 3ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆï¼ˆæ¨å¥¨ï¼‰
    sora2_prompt: str = ''  # Sora 2ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆï¼ˆæ¨å¥¨ï¼‰
    recommended_model: str = 'Veo 3'  # æ¨å¥¨ãƒ¢ãƒ‡ãƒ«
```

2. **Veo 3ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆç”Ÿæˆ**:
   - **ç‰¹å¾´**: æ§‹é€ åŒ–ã•ã‚ŒãŸæŠ€è¡“çš„ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ
   - **å½¢å¼**: ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿åˆ—æŒ™å‹

```python
def _generate_veo3_prompt(
    self,
    cut_info: Dict,
    camera_movement: str,
    duration: int
) -> str:
    """Generate Veo 3 prompt for video generation"""
    # Veo 3ç”¨ã®ã‚«ãƒ¡ãƒ©ãƒ ãƒ¼ãƒ–ãƒ¡ãƒ³ãƒˆè¨˜è¿°
    movement_desc = {
        'static': 'Camera: Static shot with minimal natural drift',
        'slow_zoom_in': 'Camera: Slow zoom in, gradually revealing details',
        'slow_zoom_out': 'Camera: Slow zoom out, expanding view',
        'pan_left': 'Camera: Smooth pan left across the scene',
        'pan_right': 'Camera: Smooth pan right across the scene',
        'tilt_up': 'Camera: Gentle tilt up, revealing sky or upper elements',
        'tilt_down': 'Camera: Gentle tilt down to ground level',
        'slow_pan': 'Camera: Slow, deliberate pan motion',
    }.get(camera_movement, 'Camera: Subtle movement')

    # Veo 3ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆæ§‹ç¯‰ï¼ˆæ§‹é€ åŒ–å½¢å¼ï¼‰
    prompt_parts = [
        f"Duration: {duration} seconds.",
        f"{movement_desc}.",
        f"Action: {cut_info.get('action', 'Natural movement and atmosphere')}.",
        f"Mood: {cut_info.get('mood', 'neutral')} atmosphere.",
        "Maintain composition and subject from the reference image.",
        "Cinematic quality with natural motion."
    ]

    return ' '.join(prompt_parts)
```

3. **Sora 2ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆç”Ÿæˆ**:
   - **ç‰¹å¾´**: è‡ªç„¶è¨€èªã«ã‚ˆã‚‹ç‰©èªå‹ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ
   - **å½¢å¼**: æµã‚Œã‚‹ã‚ˆã†ãªæå†™çš„è¨˜è¿°

```python
def _generate_sora2_prompt(
    self,
    cut_info: Dict,
    camera_movement: str,
    duration: int
) -> str:
    """Generate Sora 2 prompt for video generation"""
    # Sora 2ç”¨ã®ã‚«ãƒ¡ãƒ©ãƒ ãƒ¼ãƒ–ãƒ¡ãƒ³ãƒˆè¨˜è¿°ï¼ˆã‚ˆã‚Šè‡ªç„¶è¨€èªçš„ï¼‰
    movement_desc = {
        'static': 'The camera remains still, capturing a static moment with only slight natural movement',
        'slow_zoom_in': 'The camera slowly zooms in, gradually revealing finer details of the scene',
        'slow_zoom_out': 'The camera gently zooms out, broadening the view and revealing more context',
        'pan_left': 'The camera pans smoothly to the left, following the natural flow of the scene',
        'pan_right': 'The camera pans gracefully to the right, unveiling new elements',
        'tilt_up': 'The camera tilts upward, revealing the sky or upper architectural elements',
        'tilt_down': 'The camera tilts downward, bringing focus to ground-level details',
        'slow_pan': 'The camera moves in a slow, deliberate pan, allowing viewers to absorb the scene',
    }.get(camera_movement, 'The camera moves subtly')

    # Sora 2ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆæ§‹ç¯‰ï¼ˆã‚ˆã‚Šè©³ç´°ãªè‡ªç„¶è¨€èªè¨˜è¿°ï¼‰
    scene_desc = cut_info.get('scene_description', '')
    action = cut_info.get('action', 'natural movement')
    mood = cut_info.get('mood', 'neutral')
    lighting = cut_info.get('lighting', 'natural lighting')

    prompt = f"""{scene_desc}. {action}. {movement_desc}. The {duration}-second shot captures a {mood} atmosphere with {lighting}. The composition maintains visual consistency with the reference image while allowing natural, cinematic motion.""".strip()

    return prompt
```

4. **ãƒ¬ãƒãƒ¼ãƒˆå‡ºåŠ›å¯¾å¿œ**:

```python
# Video generation prompts (Veo 3 ã¨ Sora 2)
if cut.veo3_prompt:
    report.append(f"\n**Veo 3 Prompt**:\n```\n{cut.veo3_prompt}\n```\n")
if cut.sora2_prompt:
    report.append(f"\n**Sora 2 Prompt**:\n```\n{cut.sora2_prompt}\n```\n")
if cut.recommended_model:
    report.append(f"\n**Recommended Model**: {cut.recommended_model}\n")

# å¾Œæ–¹äº’æ›æ€§: video_promptãŒå­˜åœ¨ã—ã€ã‹ã¤Veo3/Sora2ãŒç©ºã®å ´åˆã®ã¿è¡¨ç¤º
if cut.video_prompt and not (cut.veo3_prompt or cut.sora2_prompt):
    report.append(f"\n**Video Prompt** (Legacy):\n```\n{cut.video_prompt}\n```\n")
```

**ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆç‰¹æ€§æ¯”è¼ƒ**:

| ç‰¹æ€§ | Veo 3 | Sora 2 |
|------|-------|--------|
| **æ§‹é€ ** | ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿åˆ—æŒ™å‹ | ç‰©èªãƒ»æå†™å‹ |
| **è¨˜è¿°ã‚¹ã‚¿ã‚¤ãƒ«** | æŠ€è¡“çš„ãƒ»æ˜ç¤ºçš„ | è‡ªç„¶è¨€èªãƒ»è©©çš„ |
| **ã‚«ãƒ¡ãƒ©è¨˜è¿°** | `Camera: Static shot` | `The camera remains still` |
| **æ™‚é–“åˆ¶å¾¡** | `Duration: 8 seconds.` | `The 8-second shot` |
| **æ¨å¥¨ç”¨é€”** | ç²¾å¯†ãªå‹•ä½œåˆ¶å¾¡ãŒå¿…è¦ãªã‚·ãƒ¼ãƒ³ | é›°å›²æ°—ãƒ»æ„Ÿæƒ…é‡è¦–ã®ã‚·ãƒ¼ãƒ³ |

**å¾Œæ–¹äº’æ›æ€§**:
- `video_prompt`ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã¯ç©ºæ–‡å­—åˆ—ã§ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆä¿æŒ
- æ—¢å­˜ã®ã‚·ã‚¹ãƒ†ãƒ ã¸ã®å½±éŸ¿ã‚’æœ€å°åŒ–
- Veo3/Sora2ãŒæœªç”Ÿæˆã®å ´åˆã¯legacyãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’è¡¨ç¤º

---

### 7.6 æœªå®Ÿè£…ãƒ»é€²è¡Œä¸­ã®ä½œæ¥­ï¼ˆ2025å¹´1æœˆæ™‚ç‚¹ï¼‰

#### ğŸŸ¡ æ¨å¥¨å„ªå…ˆåº¦ï¼ˆRecommended Priorityï¼‰

##### 7.6.1 ãƒ—ãƒ©ã‚°ã‚¤ãƒ³å‡¦ç†ã®ã‚¿ã‚¤ãƒŸãƒ³ã‚°å•é¡Œ

**èª²é¡Œ**:
- `ShirahamaTourismPlugin`ã®`_post_generation_processing()`ãŒ`data: Dict`ã‚’æœŸå¾…
- ã—ã‹ã—å®Ÿéš›ã«ã¯`StoryboardData`ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆãŒæ¸¡ã•ã‚Œã‚‹
- å‹ã®ä¸ä¸€è‡´ã«ã‚ˆã‚Šç´ æé¸æŠå‡¦ç†ãŒæ­£ã—ãå‹•ä½œã—ãªã„å¯èƒ½æ€§

**å½±éŸ¿ç¯„å›²**:
- `projects/nanki-shirahama-2024/plugins/shirahama_tourism_plugin.py`
- ãƒ—ãƒ©ã‚°ã‚¤ãƒ³ã®ç´ æé¸æŠæ©Ÿèƒ½å…¨èˆ¬

**è§£æ±ºç­–æ¡ˆ**:
1. ãƒ—ãƒ©ã‚°ã‚¤ãƒ³ã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹ã‚’`StoryboardData`å¯¾å¿œã«å¤‰æ›´
2. ã¾ãŸã¯ã€`StoryboardData.to_dict()`ã‚’å‘¼ã³å‡ºã—ã¦ã‹ã‚‰æ¸¡ã™
3. ãƒ—ãƒ©ã‚°ã‚¤ãƒ³ã§ä¸¡æ–¹ã®å‹ã‚’ã‚µãƒãƒ¼ãƒˆ

**å®Ÿè£…å„ªå…ˆåº¦**: ğŸŸ¡ æ¨å¥¨ï¼ˆç™½æµœãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆå®Ÿè¡Œæ™‚ã«å¿…é ˆï¼‰

---

##### 7.6.2 ç´ æé¸æŠã‚¨ãƒ©ãƒ¼ã®ãƒ¬ãƒãƒ¼ãƒˆè¡¨ç¤º

**èª²é¡Œ**:
- `material_not_found`, `material_selection_error`ã‚¨ãƒ©ãƒ¼ãŒJSONã«ã¯è¨˜éŒ²ã•ã‚Œã‚‹
- ã—ã‹ã—Markdownãƒ¬ãƒãƒ¼ãƒˆã«ã¯è¡¨ç¤ºã•ã‚Œãªã„
- ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒç´ æé¸æŠã®å¤±æ•—ã«æ°—ä»˜ã‘ãªã„

**å®Ÿè£…ã™ã¹ãå†…å®¹**:
1. ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆæ™‚ã«image_generation_errorsã‚’ç¢ºèª
2. ç´ æé¸æŠã‚¨ãƒ©ãƒ¼ã‚’å°‚ç”¨ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã§è¡¨ç¤º
3. ã‚¨ãƒ©ãƒ¼ã‚¿ã‚¤ãƒ—åˆ¥ã®å¯¾å‡¦æ³•ã‚’æç¤º

**ã‚³ãƒ¼ãƒ‰ä¾‹**ï¼ˆè¿½åŠ äºˆå®šï¼‰:
```python
# storyboard_generator.py ã® _generate_report() ãƒ¡ã‚½ãƒƒãƒ‰ã«è¿½åŠ 
if hasattr(storyboard, 'image_generation_errors') and storyboard.image_generation_errors:
    errors = storyboard.image_generation_errors.get('errors', [])
    material_errors = [e for e in errors if 'material' in e.get('type', '')]

    if material_errors:
        report.append("\n## âš ï¸ Material Selection Issues\n\n")
        for error in material_errors:
            report.append(f"- **Cut {error['cut_number']}**: {error['message']}\n")
            if error['type'] == 'material_not_found':
                report.append(f"  - Suggestion: Check available materials in categories: {error.get('categories', [])}\n")
```

**å®Ÿè£…å„ªå…ˆåº¦**: ğŸŸ¡ æ¨å¥¨ï¼ˆãƒ¦ãƒ¼ã‚¶ãƒ“ãƒªãƒ†ã‚£å‘ä¸Šï¼‰

---

##### 7.6.3 ãƒ¬ãƒãƒ¼ãƒˆã¸ã®ç´ ææƒ…å ±è¡¨ç¤º

**èª²é¡Œ**:
- å„ã‚«ãƒƒãƒˆã§ã©ã®ç´ æå†™çœŸãŒé¸ã°ã‚ŒãŸã‹è¡¨ç¤ºã•ã‚Œãªã„
- ãƒ‡ãƒãƒƒã‚°ã‚„å“è³ªç¢ºèªãŒå›°é›£

**å®Ÿè£…ã™ã¹ãå†…å®¹**:
1. CutDataè©³ç´°ã«ç´ ææƒ…å ±ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã‚’è¿½åŠ 
2. ç´ æãƒ•ã‚¡ã‚¤ãƒ«åã€ã‚«ãƒ†ã‚´ãƒªã€ãƒ‘ã‚¹ã‚’è¡¨ç¤º
3. ç´ æã®ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ï¼ˆæ’®å½±å ´æ‰€ã€æ™‚é–“å¸¯ãªã©ï¼‰ã‚‚è¡¨ç¤º

**ã‚³ãƒ¼ãƒ‰ä¾‹**ï¼ˆè¿½åŠ äºˆå®šï¼‰:
```python
# storyboard_generator.py ã® _generate_report() ãƒ¡ã‚½ãƒƒãƒ‰ã«è¿½åŠ 
if hasattr(cut, 'material_photo_name') and cut.material_photo_name:
    report.append("\n**Material Information**:\n")
    report.append(f"- Photo: `{cut.material_photo_name}`\n")
    if hasattr(cut, 'material_category'):
        report.append(f"- Category: {cut.material_category}\n")
    if hasattr(cut, 'material_photo_path'):
        report.append(f"- Path: `{cut.material_photo_path}`\n")
```

**å®Ÿè£…å„ªå…ˆåº¦**: ğŸŸ¡ æ¨å¥¨ï¼ˆå“è³ªç®¡ç†å‘ä¸Šï¼‰

---

##### 7.6.4 å‚ç…§ç”»åƒã®æŸ”è»Ÿä½¿ç”¨ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆä¿®æ­£

**èƒŒæ™¯**:
- ç™½æµœãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã®æ–°ã—ã„åˆ¶ç´„:
  - èƒŒæ™¯ç”»åƒã¨å®Œå…¨ä¸€è‡´ä¸è¦ï¼ˆæ™‚é–“å¸¯å¤‰æ›´å¯: æ˜¼â†’å¤•æ–¹/å¤œï¼‰
  - ãŸã ã—åŸºæœ¬çš„ãªãƒ©ãƒ³ãƒ‰ãƒãƒ¼ã‚¯ãƒ»é¢¨æ™¯ã¯ä¿æŒ
  - ç™½æµœç”ºã«å­˜åœ¨ã™ã‚‹æ™¯è‰²ã®ã¿

**èª²é¡Œ**:
- ç¾åœ¨ã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã¯ã€ŒMaintain composition and subject from the reference imageã€ï¼ˆå³æ ¼ï¼‰
- æ™‚é–“å¸¯å¤‰æ›´ã®æŸ”è»Ÿæ€§ã‚’åæ˜ ã—ã¦ã„ãªã„

**å®Ÿè£…ã™ã¹ãå†…å®¹**:
1. ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã«æ™‚é–“å¸¯ã®æŸ”è»Ÿæ€§ã‚’è¿½åŠ 
2. ãƒ©ãƒ³ãƒ‰ãƒãƒ¼ã‚¯ä¿æŒã®é‡è¦æ€§ã‚’æ˜ç¤º
3. ç™½æµœãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆå°‚ç”¨ã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆä¿®é£¾å­

**ã‚³ãƒ¼ãƒ‰ä¾‹**ï¼ˆè¿½åŠ äºˆå®šï¼‰:
```python
# shirahama_tourism_plugin.py ã«è¿½åŠ 
def modify_image_prompt_for_flexibility(self, prompt: str, time_of_day: str) -> str:
    """
    æ™‚é–“å¸¯ã®æŸ”è»Ÿæ€§ã‚’åæ˜ ã—ãŸãƒ—ãƒ­ãƒ³ãƒ—ãƒˆä¿®æ­£

    Args:
        prompt: å…ƒã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ
        time_of_day: å¸Œæœ›ã™ã‚‹æ™‚é–“å¸¯ (day, evening, night)
    """
    flexibility_note = """
    Preserve the essential landmarks and scenery composition from the reference image,
    but you may adjust lighting and atmosphere to match {time_of_day} conditions.
    Keep recognizable features of Shirahama landmarks intact.
    """.format(time_of_day=time_of_day)

    return prompt + " " + flexibility_note.strip()
```

**å®Ÿè£…å„ªå…ˆåº¦**: ğŸŸ¡ æ¨å¥¨ï¼ˆç™½æµœãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã®æ–°è¦ä»¶å¯¾å¿œï¼‰

---

#### ğŸŸ¢ ã‚ªãƒ—ã‚·ãƒ§ãƒ³å„ªå…ˆåº¦ï¼ˆOptionalï¼‰

##### 7.6.5 ã‚­ãƒ£ãƒ©å‚ç…§ç”»åƒã®æ¤œè¨¼å¼·åŒ–

**èª²é¡Œ**:
- Gemini 2.5 Flash Imageã®3ç”»åƒåˆ¶é™
- ç™½æµœãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆ: ã‚­ãƒ£ãƒ©2æš + èƒŒæ™¯1æšã‚’æ¨å¥¨
- ç¾çŠ¶ã¯åˆ¶é™è¶…éæ™‚ã®è­¦å‘Šãªã—

**å®Ÿè£…ã™ã¹ãå†…å®¹**:
```python
def validate_reference_images(self, cut: CutData, project_type: str = 'general'):
    """å‚ç…§ç”»åƒã®å¦¥å½“æ€§ãƒã‚§ãƒƒã‚¯"""
    if not hasattr(cut, 'reference_images') or not cut.reference_images:
        return True

    num_refs = len(cut.reference_images)

    if num_refs > 3:
        print(f"âš ï¸  Cut {cut.cut_number}: {num_refs} reference images exceed Gemini limit (max 3)")
        return False

    if project_type == 'shirahama_tourism' and num_refs > 2:
        print(f"âš ï¸  Cut {cut.cut_number}: Shirahama project recommends max 2 character refs + 1 background")

    return True
```

**å®Ÿè£…å„ªå…ˆåº¦**: ğŸŸ¢ ã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼ˆå“è³ªå‘ä¸Šï¼‰

---

##### 7.6.6 å‚ç…§ç”»åƒãƒ•ã‚¡ã‚¤ãƒ«å­˜åœ¨ãƒã‚§ãƒƒã‚¯

**èª²é¡Œ**:
- ç”»åƒç”Ÿæˆæ™‚ã«ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚‰ãªã„å ´åˆã€å®Ÿè¡Œæ™‚ã‚¨ãƒ©ãƒ¼
- äº‹å‰ãƒã‚§ãƒƒã‚¯ã§æ—©æœŸç™ºè¦‹å¯èƒ½

**å®Ÿè£…ã™ã¹ãå†…å®¹**:
```python
def check_reference_images_exist(self, storyboard: StoryboardData) -> List[str]:
    """å…¨ã‚«ãƒƒãƒˆã®å‚ç…§ç”»åƒã®å­˜åœ¨ç¢ºèª"""
    missing_files = []

    for cut in storyboard.cuts:
        if hasattr(cut, 'reference_images') and cut.reference_images:
            for ref_path in cut.reference_images:
                if not Path(ref_path).exists():
                    missing_files.append(f"Cut {cut.cut_number}: {ref_path}")

    if missing_files:
        print("âš ï¸  Missing reference images:")
        for missing in missing_files:
            print(f"  - {missing}")

    return missing_files
```

**å®Ÿè£…å„ªå…ˆåº¦**: ğŸŸ¢ ã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼ˆã‚¨ãƒ©ãƒ¼äºˆé˜²ï¼‰

---

## 8. ãƒ†ã‚¹ãƒˆã‚±ãƒ¼ã‚¹

### 8.1 å˜ä½“ãƒ†ã‚¹ãƒˆ
- ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆç”Ÿæˆãƒ­ã‚¸ãƒƒã‚¯
- APIæ¥ç¶šã¨ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°
- ãƒ‡ãƒ¼ã‚¿æ§‹é€ ã®æ¤œè¨¼

### 8.2 çµ±åˆãƒ†ã‚¹ãƒˆ
- ã‚¨ãƒ³ãƒ‰ãƒ„ãƒ¼ã‚¨ãƒ³ãƒ‰ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼
- ç•°ãªã‚‹ã‚¹ãƒˆãƒ¼ãƒªãƒ¼ã‚¿ã‚¤ãƒ—ã§ã®ç”Ÿæˆ
- ã‚¨ãƒ©ãƒ¼å¾©æ—§å‡¦ç†

### 8.3 ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ†ã‚¹ãƒˆ
- 10ã‚«ãƒƒãƒˆç”Ÿæˆã®æ‰€è¦æ™‚é–“
- APIåˆ¶é™ä¸‹ã§ã®å‹•ä½œ
- ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡

## 9. ä»Šå¾Œã®æ‹¡å¼µè¨ˆç”»

### Phase 1ï¼ˆåˆæœŸãƒªãƒªãƒ¼ã‚¹ï¼‰
- âœ… åŸºæœ¬çš„ãªçµµã‚³ãƒ³ãƒ†ç”Ÿæˆ
- âœ… Imagen 3ã§ã®ç”»åƒç”Ÿæˆ
- âœ… ItoVãƒ—ãƒ­ãƒ³ãƒ—ãƒˆç”Ÿæˆ
- âœ… åŸºæœ¬çš„ãªæ§‹å›³ãƒ»ã‚«ãƒ¡ãƒ©ãƒ¯ãƒ¼ã‚¯

### Phase 2ï¼ˆæ©Ÿèƒ½æ‹¡å¼µï¼‰
- ğŸ”„ éŸ³å£°ãƒ»BGMåŒæœŸæ©Ÿèƒ½
- ğŸ”„ ãƒˆãƒ©ãƒ³ã‚¸ã‚·ãƒ§ãƒ³è¨­è¨ˆ
- ğŸ”„ æ„Ÿæƒ…æ›²ç·šã®å¯è¦–åŒ–
- ğŸ”„ è¤‡æ•°ã‚¹ã‚¿ã‚¤ãƒ«ã®ã‚µãƒãƒ¼ãƒˆ

### Phase 3ï¼ˆé«˜åº¦ãªæ©Ÿèƒ½ï¼‰
- ğŸ“‹ ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼
- ğŸ“‹ å”èª¿ç·¨é›†æ©Ÿèƒ½
- ğŸ“‹ AIãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ãƒ«ãƒ¼ãƒ—
- ğŸ“‹ è‡ªå‹•å“è³ªè©•ä¾¡

## 10. ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆç®¡ç†

### 10.1 æ›´æ–°å±¥æ­´
- v1.0.0: åˆæœŸãƒªãƒªãƒ¼ã‚¹
- v1.1.0: ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼ç®¡ç†æ©Ÿèƒ½è¿½åŠ 
- v1.2.0: ã‚«ã‚¹ã‚¿ãƒ ã‚¹ã‚¿ã‚¤ãƒ«å¯¾å¿œ

### 10.2 ãƒ¡ãƒ³ãƒ†ãƒŠãƒ³ã‚¹
- æœˆæ¬¡ã§ã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒ‘ã‚¿ãƒ¼ãƒ³æ›´æ–°
- APIå¤‰æ›´ã¸ã®å¯¾å¿œ
- ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã®åæ˜ 

## 11. ãƒ©ã‚¤ã‚»ãƒ³ã‚¹ã¨åˆ¶é™äº‹é …

### 11.1 ãƒ©ã‚¤ã‚»ãƒ³ã‚¹
- MITãƒ©ã‚¤ã‚»ãƒ³ã‚¹ï¼ˆã‚ªãƒ¼ãƒ—ãƒ³ã‚½ãƒ¼ã‚¹ï¼‰
- Gemini APIåˆ©ç”¨è¦ç´„ã«æº–æ‹ 

### 11.2 åˆ¶é™äº‹é …
- Gemini APIã‚­ãƒ¼ãŒå¿…é ˆ
- 1åˆ†é–“ã®å‹•ç”»ã«æœ€é©åŒ–ï¼ˆå»¶é•·ã¯è¦èª¿æ•´ï¼‰
- ç”Ÿæˆç”»åƒã®å•†ç”¨åˆ©ç”¨ã¯Geminiè¦ç´„ã«å¾“ã†

## 12. ã‚µãƒãƒ¼ãƒˆã¨ã‚³ãƒŸãƒ¥ãƒ‹ãƒ†ã‚£

### 12.1 ã‚µãƒãƒ¼ãƒˆãƒãƒ£ãƒãƒ«
- GitHubã‚¤ã‚·ãƒ¥ãƒ¼
- ãƒ‡ã‚£ã‚¹ã‚«ãƒƒã‚·ãƒ§ãƒ³ãƒ•ã‚©ãƒ¼ãƒ©ãƒ 
- å®šæœŸçš„ãªãƒ¯ãƒ¼ã‚¯ã‚·ãƒ§ãƒƒãƒ—

### 12.2 è²¢çŒ®ã‚¬ã‚¤ãƒ‰ãƒ©ã‚¤ãƒ³
- ãƒ—ãƒ«ãƒªã‚¯ã‚¨ã‚¹ãƒˆã®å—ã‘å…¥ã‚Œ
- ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒ‘ã‚¿ãƒ¼ãƒ³ã®å…±æœ‰
- ä½¿ç”¨äº‹ä¾‹ã®æŠ•ç¨¿

---

## ä»˜éŒ²A: ç”¨èªé›†

- **ItoV (Image to Video)**: é™æ­¢ç”»ã‹ã‚‰å‹•ç”»ã‚’ç”Ÿæˆã™ã‚‹æŠ€è¡“
- **Imagen 3**: Googleã®AIç”»åƒç”Ÿæˆãƒ¢ãƒ‡ãƒ«
- **çµµã‚³ãƒ³ãƒ†**: å‹•ç”»ã®å„ã‚·ãƒ¼ãƒ³ã‚’å›³è§£ã—ãŸè¨­è¨ˆå›³
- **ã‚«ãƒƒãƒˆ**: å‹•ç”»ã®æœ€å°å˜ä½ã€é€£ç¶šã—ãŸæ˜ åƒ
- **æ§‹å›³**: ç”»é¢å†…ã®è¦ç´ ã®é…ç½®æ–¹æ³•
- **ã‚«ãƒ¡ãƒ©ãƒ¯ãƒ¼ã‚¯**: ã‚«ãƒ¡ãƒ©ã®å‹•ãã‚„æŠ€æ³•

## ä»˜éŒ²B: ã‚ˆãã‚ã‚‹è³ªå•ï¼ˆFAQï¼‰

**Q1: Gemini APIã‚­ãƒ¼ã¯ã©ã“ã§å–å¾—ã§ãã¾ã™ã‹ï¼Ÿ**
A: Google AI Studioã‹ã‚‰å–å¾—ã§ãã¾ã™ã€‚

**Q2: 1åˆ†ä»¥ä¸Šã®å‹•ç”»ã¯ä½œæˆã§ãã¾ã™ã‹ï¼Ÿ**
A: å¯èƒ½ã§ã™ãŒã€ã‚«ãƒƒãƒˆæ•°ã¨ã‚³ã‚¹ãƒˆãŒå¢—åŠ ã—ã¾ã™ã€‚

**Q3: ç”Ÿæˆã•ã‚ŒãŸç”»åƒã®è‘—ä½œæ¨©ã¯ï¼Ÿ**
A: Gemini APIã®åˆ©ç”¨è¦ç´„ã«å¾“ã„ã¾ã™ã€‚

**Q4: ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼ã®ä¸€è²«æ€§ã¯ã©ã®ç¨‹åº¦ä¿è¨¼ã•ã‚Œã¾ã™ã‹ï¼Ÿ**
A: å®Œå…¨ãªä¸€è²«æ€§ã¯å›°é›£ã§ã™ãŒã€è©³ç´°ãªãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã§æ”¹å–„å¯èƒ½ã§ã™ã€‚

**Q5: ä»–ã®AIç”»åƒç”Ÿæˆãƒ¢ãƒ‡ãƒ«ã¯ä½¿ç”¨ã§ãã¾ã™ã‹ï¼Ÿ**
A: ã‚¹ã‚¯ãƒªãƒ—ãƒˆã®æ”¹ä¿®ã«ã‚ˆã‚Šå¯¾å¿œå¯èƒ½ã§ã™ã€‚

---

*æœ€çµ‚æ›´æ–°: 2025å¹´10æœˆ29æ—¥*
*ãƒãƒ¼ã‚¸ãƒ§ãƒ³: 1.0.0*
